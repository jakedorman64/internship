{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMW1druvYiuqXBTjVE+K/Nb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakedorman64/internship/blob/main/Double_Pendulum_NeuralODE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Double Pendulum Simulator\n",
        "\n",
        "Solving the Euler Lagrange equations for the double pendulum gives the second order differential equations:\n",
        "\n",
        "$$ \\begin{align} \\ddot{\\theta}_1 & = \\frac{g \\sin{\\theta_2} \\cos{(\\theta_1 - \\theta_2)} - \\sin{(\\theta_1 - \\theta_2)} \\left[ \\dot{\\theta}_1^2 \\cos{(\\theta_1 - \\theta_2)} + \\dot{\\theta}_2^2\\right] - 2 g \\sin{\\theta_1}}{1 + \\sin^2{(\\theta_1 - \\theta_2)}}\n",
        "\\\\\n",
        " \\ddot{\\theta}_2 & = \\frac{2 \\left[ \\dot{\\theta}_1^2 \\sin{(\\theta_1 - \\theta_2)} - g \\sin{\\theta_2} + g \\sin{\\theta_1} \\cos {(\\theta_1 - \\theta_2)} \\right] + \\dot{\\theta}_2^2 \\sin{(\\theta_1 - \\theta_2)} \\cos{(\\theta_1 - \\theta_2)}}{1 + \\sin^2{(\\theta_1 - \\theta_2)}} \\end{align} $$\n",
        "\n",
        "Note that we have set mass and length of both sections to be 1. We need a system of first order differential equations. Thus, we will define $ \\omega = \\dot{\\theta} $ for each section, thus giving us the system of equations:\n",
        "\n",
        "$$ \\begin{align} \\frac{d \\omega_1}{dt} & = \\frac{g \\sin{\\theta_2} \\cos{(\\theta_1 - \\theta_2)} - \\sin{(\\theta_1 - \\theta_2)} \\left[ \\omega_1^2 \\cos{(\\theta_1 - \\theta_2)} + \\omega_2^2\\right] - 2 g \\sin{\\theta_1}}{1 + \\sin^2{(\\theta_1 - \\theta_2)}}\n",
        "\\\\\n",
        " \\frac{d \\omega_2}{dt} & = \\frac{2 \\left[ \\omega_1^2 \\sin{(\\theta_1 - \\theta_2)} - g \\sin{\\theta_2} + g \\sin{\\theta_1} \\cos {(\\theta_1 - \\theta_2)} \\right] + \\omega_2^2 \\sin{(\\theta_1 - \\theta_2)} \\cos{(\\theta_1 - \\theta_2)}}{1 + \\sin^2{(\\theta_1 - \\theta_2)}} \\end{align} $$\n",
        " Plus the simpler equations:\n",
        " $$\\begin{align} \\frac{d \\theta_1}{dt} & = \\omega_1 \\\\ \\frac{d \\theta_2}{dt} & = \\omega_2. \\end{align} $$"
      ],
      "metadata": {
        "id": "uYyB_o-3Pi-q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate the Data"
      ],
      "metadata": {
        "id": "GnSdOh88tYR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/deepmind/dm-haiku\n",
        "!pip install gplearn"
      ],
      "metadata": {
        "id": "Yv4-XZC31vsL",
        "outputId": "76d688a0-2698-4b0a-8b8c-a6620f1d2460",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/deepmind/dm-haiku\n",
            "  Cloning https://github.com/deepmind/dm-haiku to /tmp/pip-req-build-qqap96_3\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/deepmind/dm-haiku /tmp/pip-req-build-qqap96_3\n",
            "  Resolved https://github.com/deepmind/dm-haiku to commit 6526bc819af6c7a3105312449fb05987dce5848a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from dm-haiku==0.0.11.dev0) (1.4.0)\n",
            "Collecting jmp>=0.0.2 (from dm-haiku==0.0.11.dev0)\n",
            "  Downloading jmp-0.0.4-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from dm-haiku==0.0.11.dev0) (1.22.4)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from dm-haiku==0.0.11.dev0) (0.9.0)\n",
            "Building wheels for collected packages: dm-haiku\n",
            "  Building wheel for dm-haiku (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dm-haiku: filename=dm_haiku-0.0.11.dev0-py3-none-any.whl size=360353 sha256=c78fa7e95b01715636505bff4974925e1a96549a416e640436b9a4a9d7f766a2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-iezt1kkv/wheels/b1/df/f1/a357fa8f00c36052bdae1e1fd363650c0bd1e8c3959487b6fb\n",
            "Successfully built dm-haiku\n",
            "Installing collected packages: jmp, dm-haiku\n",
            "Successfully installed dm-haiku-0.0.11.dev0 jmp-0.0.4\n",
            "Collecting gplearn\n",
            "  Downloading gplearn-0.4.2-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from gplearn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gplearn) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->gplearn) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->gplearn) (3.2.0)\n",
            "Installing collected packages: gplearn\n",
            "Successfully installed gplearn-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q-s-fsTrPiQb",
        "outputId": "3f8c7024-6e6c-4a38-b9c4-2c8c9ef8e7a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpu\n"
          ]
        }
      ],
      "source": [
        "from typing import Iterator, NamedTuple\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax.numpy import pi, sin, cos\n",
        "from jax import value_and_grad, jit\n",
        "from jax import random\n",
        "from jax.experimental.ode import odeint\n",
        "from jax.config import config\n",
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import time\n",
        "from tqdm.auto import trange\n",
        "from matplotlib.patches import Circle\n",
        "from functools import partial\n",
        "from sklearn.model_selection import train_test_split\n",
        "import haiku as hk\n",
        "import optax\n",
        "import numpy as np\n",
        "import gplearn as gp\n",
        "\n",
        "# This tells us whether we are on cpu or gpu.\n",
        "print(jax.lib.xla_bridge.get_backend().platform)\n",
        "\n",
        "# Disabling jit can be used for debugging. Default is false.\n",
        "config.update(\"jax_disable_jit\", False)\n",
        "# Sometimes NaNs can be generated if we are not working in x64, but x64 is slower. Default is false.\n",
        "config.update(\"jax_enable_x64\", False)\n",
        "# This causes the program to end if a NaN is detected in the jax code. Default is False.\n",
        "config.update(\"jax_debug_nans\", False)\n",
        "\n",
        "# Define our constants.\n",
        "g = - 9.81\n",
        "dt = 0.001\n",
        "data_points = 32768\n",
        "prediction_batch_size = 16\n",
        "training_batch_size = 8\n",
        "total_time = data_points * dt\n",
        "gradient_updates = 20000"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Define our target differential equation. This will be used to generate our data \"\"\"\n",
        "\n",
        "@jit\n",
        "def dy_dt(y, t, g):\n",
        "  # These our our 2 angles and 2 angular velocities.\n",
        "  theta_1 = y[0]\n",
        "  theta_2 = y[1]\n",
        "  omega_1 = y[2]\n",
        "  omega_2 = y[3]\n",
        "\n",
        "  # Make the equations nicer by setting these:\n",
        "  s = sin(theta_1 - theta_2)\n",
        "  c = cos(theta_1 - theta_2)\n",
        "\n",
        "  # Derivative of the thetas are just the omegas:\n",
        "  dtheta1_dt = omega_1\n",
        "  dtheta2_dt = omega_2\n",
        "\n",
        "  # Derivative of the omegas:\n",
        "  domega1_dt = ( g * sin(theta_2) * c - s * ((omega_1 ** 2) * c + (omega_2 ** 2)) - 2 * g * sin(theta_1) ) / (1 + s ** 2)\n",
        "\n",
        "  domega2_dt = ( 2 * ( (omega_1 ** 2) * s - g * sin(theta_2) + g * sin(theta_1) * c ) + (omega_2 ** 2) * s * c ) / (1 + s ** 2)\n",
        "\n",
        "  dy_dt = jnp.array([dtheta1_dt, dtheta2_dt, domega1_dt, domega2_dt])\n",
        "  return dy_dt"
      ],
      "metadata": {
        "id": "qYRJCOSFe2KS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Make a function to generate our initial point.\"\"\"\n",
        "\n",
        "# Cannot jit this as then simple == True will cause an error.\n",
        "def generate_initial_point(simple=False, perturb = 0.2):\n",
        "  # This will generate simple data if we want to.\n",
        "  if simple == True:\n",
        "    theta_1_init = perturb\n",
        "    theta_2_init = perturb\n",
        "    omega_1_init = 2\n",
        "    omega_2_init = 0\n",
        "  # Otherwise, generate with random initial point.\n",
        "  else:\n",
        "    key, subkey = random.split(random.PRNGKey(int(time.time())))\n",
        "    theta_1_init = random.uniform(key, minval = 0, maxval = 2 * pi)\n",
        "    theta_2_init = random.uniform(subkey, minval = 0, maxval = 2 * pi)\n",
        "\n",
        "    key, subkey = random.split(key)\n",
        "    omega_1_init = random.uniform(key, minval = -5, maxval = 5)\n",
        "    omega_2_init = random.uniform(key, minval = -5, maxval = 5)\n",
        "\n",
        "  # Create the array of our initial value.\n",
        "  init = jnp.array([theta_1_init, theta_2_init, omega_1_init, omega_2_init])\n",
        "  return init"
      ],
      "metadata": {
        "id": "DuFRifkcxqEh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Generate and print our data.\"\"\"\n",
        "\n",
        "# Make our time array:\n",
        "tsteps = jnp.linspace(0, total_time, data_points)\n",
        "\n",
        "init = generate_initial_point(True)\n",
        "generated_data = odeint(dy_dt, init, tsteps, g)\n",
        "plt.plot(generated_data[:, 0], generated_data[:, 1])"
      ],
      "metadata": {
        "id": "VlT_hRLlqAvG",
        "outputId": "b62f14de-a711-45d3-cb60-d5dc2d07fb40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ffab01f3a00>]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGdCAYAAADnrPLBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABdgElEQVR4nO3deXxU9b3/8dfsWWey7wGSAGEVEAHBDRRBi1ZbtfW27q2tXtvf7dVrkdtWbW+trd4ut9a6dFFrN7W2WncRwTWAsm8JS8i+r5N11vP7I5AmCgiSZGaS9/PxmMdkzjlz5pMckvPmnO9iMgzDQERERCRCmUNdgIiIiMjJUJgRERGRiKYwIyIiIhFNYUZEREQimsKMiIiIRDSFGREREYloCjMiIiIS0RRmREREJKJZQ13ASAgGg9TU1BAfH4/JZAp1OSIiInIcDMOgo6ODrKwszOajX38ZE2GmpqaG3NzcUJchIiIin0JlZSU5OTlHXT8mwkx8fDzQ98NwOp0hrkZERESOh9vtJjc3t/88fjRjIswcvrXkdDoVZkRERCLMJzURUQNgERERiWgKMyIiIhLRFGZEREQkoinMiIiISERTmBEREZGIpjAjIiIiEU1hRkRERCJayMPMvffey7x584iPjyctLY1LL72UkpKSQdv09vZyyy23kJycTFxcHJdddhn19fUhqlhERETCScjDzFtvvcUtt9zC+vXrWb16NT6fj2XLltHV1dW/zX/+53/ywgsv8Mwzz/DWW29RU1PD5z//+RBWLSIiIuHCZBiGEeoiBmpsbCQtLY233nqLs88+m/b2dlJTU/nzn//M5ZdfDkBxcTFTp06lqKiI008//RP36Xa7cblctLe3awRgERGRCHG85++QX5n5qPb2dgCSkpIA2LRpEz6fj6VLl/ZvM2XKFMaNG0dRUdER9+HxeHC73YMeIiIiMjqFVZgJBoN861vf4owzzmDGjBkA1NXVYbfbSUhIGLRteno6dXV1R9zPvffei8vl6n9oxmwREZHRK6wmmrzlllvYuXMn77777kntZ9WqVdx66639rw/PuikiIjLaBYMGte5e6tp7aezw0NjpobXLi9cfxBsIEgwaxNgtxDisJMXYyU2KITcpmixXNGbzsSd0DFdhE2a+8Y1v8OKLL/L222+Tk5PTvzwjIwOv10tbW9ugqzP19fVkZGQccV8OhwOHwzHcJYuIiIRMIGhwsKmL3bVu9tS6OdjYxcGmLsqau/D4gye8vziHlVNyXMzKTeC08YksLEgmxh42MeGYQl6lYRh885vf5B//+Afr1q0jLy9v0Pq5c+dis9lYs2YNl112GQAlJSVUVFSwcOHCUJQsIiIyogzD4EBjF5vLW9le3cauGjfFtR30+AJH3N5qNpHhiiI13kFqnIOkWDtRNgt2qxmTCbo9Abo8fho7PVS19lDV2k2nx8/7B5p5/0AzAHaLmXl5iSyenMY5halMSovDZArPKzch78307//+7/z5z3/m+eefp7CwsH+5y+UiOjoagJtvvpmXX36Zxx9/HKfTyTe/+U0A3n///eP6DPVmEhGRSNLt9bOtsp3NFa1sKm9lc0Urbd2+j20XbbMwJTOeaZlOJqbFMSEllvyUWLITorFajr9ZrD8QZF9DJ9sq29ha2cZ7B5qobOkZtE1eSiyfmZnBhTMymZ7lHJFgc7zn75CHmaP9MB577DGuu+46oG/QvNtuu42//OUveDweli9fzq9//euj3mb6KIUZEREJZ75AsC9E7G/ivf1NbKlowx8cfHp2WM3Myk1gTm4C07KcTM9ykZcSi2UY2rkYhkFpUxdvlTSybm8j60ub8Q64dZWXEssX5+VyxdwckuOGr1lHxISZkaAwIyIi4aaqtZvVu+t5Z18TG0qb6fIOvmWU6Yri1PGJzB2XyNzxiUzNdGK3hqYTcqfHz5vFDby8vZa1JQ39bXKibRa+dnY+3zh3IrYTuBJ0vBRmBlCYERGRUDMMg101bl7fXc/q3fXsqR08BlpijI1FE1M4c2IKZxSkMC45JkSVHluXx89L22t5cn05O6r7xob7zMwMfv3luUP+Wcd7/g55A2AREZHRrKq1m79vrubvm6soa+7uX242wWkTkjhvShpnTkphaoYzIrpGxzqsfGFeLleclsM/t9XwH3/dyss76ihr6mJCSmxIalKYERERGWLBoMGa4gZ+/+5Bikqb+5dH2cycPSmVZdMzOHdKGkmx9hBWeXIGtnk1mSDGbglZLQozIiIiQ8QwDF7ZWcfPVu9lf0Mn0HeiX5ifzGWn5nDBjAxiHZF/6jUMgwfe3M/PVu8F4NqFE0hzRoWsnsj/iYqIiIQBd6+PW5/ayht7GgCId1j58unjuer0ceQkhmf7l0+jo9fHfz2zjdd21QNw3aIJfHfF1JDWpDAjIiJykoJBg68+8SEbD7Zgt5i56Zx8vnp2Ps4oW6hLG1I1bT1c9bsNlDZ2YbeY+cEl07ly/rhQl6UwIyIicrJ21rSz8WALVrOJZ29exMwcV6hLGnJdHj9f/u0GDjZ1kemK4qGr5jI7NyHUZQFhNmu2iIhIJDrc+NUfNNha2UowOPpGPXmiqKw/yPzt5kVhE2RAYUZEROSkTUyL598O3W753vO7WPHAu7y8oxZ/4MQnfAxXO6r6xpS5euF4shOiQ1zNYAozIiIiQ+CeS2dw50XTiHdY2VPr5t//tJkzf7KWX67ZR727N9TlnbTDY8i8sbs+7EKaRgAWEREZQm3dXn7/7kH+vLGCpk4v0DdA3hkTU7h8bg7LpmUQHcIxWT6t6rYelv/8bTo9fv7fuRO5dVnhJ7/pJGk6gwEUZkREZKR5/AFe2VHHH9eX82F5a//yOIe1f/bphQXJRNkiJ9g8v7Wa//jrVgB+c81pnD8tfVg/T2FmAIUZEREJpbKmLv6+pW9Kg6rWnv7lMXYLZ05M4cxJKczJTWRKZvywTNg4lO7+5y4ef7+MtHgHb397ybCGMYWZARRmREQkHASDBh+UtfDPbTWs2dNA3Ufa0titZiYkxzAhOZYJKbFMSI4lLyWW/NRY0uIdg6YQCBWPP8Cie9+kucvLX248nYUFycP2WZpoUkREJMyYzSYW5CezID+ZH17aN4v2m8UNbCpvZUtFK+5eP3vrO9lb3/mx98bYLRSkxjE7N4FTxycwd1wSuUnRIx5w3t7bRHuPDwBXdHgMCqgrMyIiImEgGDSobO3mYFMX5c19z2XNXRxs6qKypZsjDV2TkxjNOZNTOWdyKosmphA3TPM+9foCvFncwF82VvDOviYALpiewUNXnTqsYUq3mQZQmBERkUjm9QepbO2muLaDzRWtrCtp4EBj11G3P2dyKgWpcSTF2kiMtZMYYychxjbo+UhtXfyBIO09PmrbeznQ2Mm++k4+LG9hc0UbXn9fd2yr2cQ1Cydwx4VTsFuHt32PbjOJiIiMEnarmWDQYHt1G+8faKa06ehBBuCtvY28tbfxmNs4rOZBV3J8gSDuXv9Rt890RXHpnGyunJfL+OTYE/sGhpnCjIiISBhr7/Hx3ed28sK2mkHLM11R5KfGkpsYgyvGRnOnl7f2NtLY4Tnm/qxmE/6ggccfxOP3HnGbpFg7BamxFKTGMT3bxaKCZPJTYsOiAfKRKMyIiIiEKcMwuPEPfbNxm0xw3pR0Pjs7i9Pzk0iLjzrq+xo6enljdwOv7arj/QNN+AL/alGS4YrivClpnFOYSlZCNCb6AorFDAkxdhKibVjDvHv4R6nNjIiISJiqbOnmrPvWAvD8LWcw61NM7uju9bG2uIHXd9eztriBbm+gf92UjHiunJfLlfPHheXgfWozIyIiEuGc0TZsFhO+gPGpw4YzysYls7O5ZHY2Pd4Ab+yp55/balhX0kBxXQd3v7CbX609wI8+N4Nl0zOG+DsYGZF1HUlERGQMcUXbWFKYBsBzW6tPen/RdgsXz8riN9ecxoffOZ//uWQ62QnRNHV6+NqTm3izuP6kPyMUFGZERETCWG5SDAB17UM787YrxsbVCyew9r8Wc9mpOQB85x876RlwGypSKMyIiIiEofYeH/e+soffv3cQ6Bs7ZjjYrWbu+dwMshOiqW3v5ZG3DwzL5wwntZkREREJE4ZhsLWyjee31vDs5io6Do37ct2iCVwyO2vYPjfKZmHVZ6bwjT9v4aF1B5iR5WLpMM+IPZQUZkRERELEMAzq3L1sKG3h3f1NvL+/iZoBt5Mmp8dx27JClo9Aw9wVMzN5floNq3fXc+OTH/LVM/O4bVlhWPZy+ih1zRYRERkBHn+AffWd7Kl1s6e2gz21borr3LR2+wZtF22zsGx6OpfOyeacSamYzSM3UJ0vEOT7L+zij+srAMhPieXOi6ex+FAj5JGmuZkGUJgREZGR1N7tY1dNO7tq3OyudbO7xs2Bxk78R5gt0mI2MTUznjMKUjhjYgrzJiQRbQ/t1ZA1e+q54+87+kcTXjo1nTsvmsa45JgRrUNhZgCFGRERGU493gAby1p4b38T7+5rYnet+4jbOaOsTM10MjXTybRDz5PS48LyVo6718cv39jH4++X4Q8aRNnMrLxgCtcunDBiV4sUZgZQmBERkaFkGAalTV2sK2lkXUkDGw629M8qfVhuUjTTMp1Mz3L1BZcsJ1muqLCd3+ho9jd08L3ndlFU2gzA5+dk89MvzBqR70NhZgCFGRGR0cvd66O6tYc6dy893gA93gD+YBCH1UKUzUyM3UpSrJ3UeAdJsXZsJzjvkGEYNHZ6KG3sYmd1O1sq2thc0UrtR8Z9yXJFceakvltFCwuSjzl3UqQJBg3+tKGcu1/YTSBo8Pj180akHY2mMxARkVGpormbV3fVsvFgK9uq2j5xluiPSoyxkRznwBVtwxllxRltI85hxWQCw4CgYeDu9dPW7aW500tVaw+dHv/H9mO3mJmfl8TiwlQWF6ZSkBoXcVddjpfZbOIzMzN5+K1Sqtt6qGrtCXVJgyjMiIhIRNhZ3c6PXynm3f1NH1uXEGMj0xVNvMNKlN2C1WzC4w/Q6wvS5fHT3OWlpctLIGjQ2u37WA+iT2IyQU5iNIXpTk4dn8Cc3ERm5bqIsQ/NabTb66e6tYfqth5q23tx9/jo8QXo8QWwmc1E2cxE2SzkJEZTkBrHuOQYHNaRaWfT1OnhLxsq+P17B2nt9pEQY2PZ9PAag0ZhRkREwt66kgZu/MOH+AIGZhMsLEhmSWEac8YlUJjhJM7xyaezYNCgtdtLU6eX5k4P7l4f7h4/7l5f/+B0JhOYTSbiHH23phJibGQnRA95eChr6uKtvY1srmhlZ3U7pU1dnEijD4vZRO6hYFOQFkdBaiz5qXEUpMaRFGs/qdoCQYM9tW42Hmxh9e56Nhxs5nAnrCkZ8fziytlhdwtNYUZERMLeT14twRcwWFyYyg8vnUFO4ol3ETabTSTHOUiOcwDxQ1/kJ6hp6+GpDyp5fms1Zc3dH1vvjLKSlRBNVkI0CdE2ou0WomwWAkGDHm+ALq+fypZuDjR20enxU9bcTVlzN2uKGwbtJzHGRn5qHOOTYshNimFcUgxJsXach26rmUwQNPrGlGnt8tHc5aHe3UtpYxf7Gzopruv42G21WbkJ3HDGBD4zM/OE2xyNBIUZEREJe15/3+SHnz8151MFmVBq7/Hx09dL+OP68v4rHDaLidPGJ7GoIJkZOS5mZLlIjXcc1/4Mw6Chw8OBhk4ONHX1PTd2UtrYRXVbD63dPjaVt7KpvPVT1xzvsDJ3QiKLCpK5cEZm/2SX4UphRkREwt65U9I40HiQdcUNfHbW8M1RNNS6PH6++EgRxXUdAJyen8S/zR/HeVPTj+vW2JGYTCbSnVGkO6NYNDFl0Lpur5+DTV0cbOqioqWbiuZuqlp7aOvx0t7TdzvNRN+tNLPZRGKMjaRYOylxDvJT45iYFsfk9DgmpcVjGcGRh0+WwoyIiIS9mTkJAP2hIFI8t7Wa4roOEmNsPPjlU1lUkPLJbzoJMXYr07NcTM9yDevnhJvwu/ElIiIywLv7mvjJK8UATM2MrLHCgofuK1ktZlLjju82kpy4iAkzDz74IBMmTCAqKooFCxawcePGUJckIiLDpKq1mz8UlXHRA+9w1e82UN3WQ15KLN++oDDUpZ2QS+dkk58aS2OHh4seeJdH3z6APxD85DfKCYmIEYCfeuoprrnmGh5++GEWLFjAL37xC5555hlKSkpIS/vkEQg1ArCISHjyB4I0dnooa+o+NJu0mw/LWznY1NW/jc1i4ssLxvOfSyfjirGFsNpPp7HDw389s4239jYCMDPbxU8uO4VpWToffZJRNZ3BggULmDdvHr/61a8ACAaD5Obm8s1vfpM77rjjE9+vMCMiMnye/rCSl7bXEjSMvkeQf31t8K/noDHo6/YeHw0dvRxhImksZhOzcxO4cEYGnz8156THTgk1wzB4+sNKfvjSHjp6/VjNJr5+Tj7fPHdSWE4yGS5GzXQGXq+XTZs2sWrVqv5lZrOZpUuXUlRUdMT3eDwePJ5/DW/tdh959lIRETl5Bw8NAPdpWc0mMhOimJLRN4v0zGwXC/KTcEZF3lWYozGZTHxx3jiWFKZx1z938crOOh5ce4BXdtTxy3+bw4zssdVgd6iFfZhpamoiEAiQnj546OT09HSKi4uP+J57772X73//+yNRnojImLdiZiYTU+Mwmw91+e1/9J3ELea+rw93Bz78dazDSpYriuQ4R0R1Az4Zac4oHrpqLq/urON7z++ktKmLf/vNev5y4+kKNCch7MPMp7Fq1SpuvfXW/tdut5vc3NwQViQiMnrNyHbpRHyCLpiRwcL8ZL76hw/4oKyVbz21lVf/4yysYTi6biQI+59aSkoKFouF+vr6Qcvr6+vJyMg44nscDgdOp3PQQ0REJJy4Ymz89pp5uKJt7G/o5IOyTz9i71gX9mHGbrczd+5c1qxZ078sGAyyZs0aFi5cGMLKRERETo4rxsa5U/p65b67/9O3Oxrrwj7MANx666385je/4YknnmDPnj3cfPPNdHV1cf3114e6NBERkZOysCAZgD9vqOC9/U0hriYyRUSbmS9+8Ys0NjZy5513UldXx+zZs3n11Vc/1ihYREQk0lx8ShaPv1fG7lo3X/7tBhbkJfGlBeNYPj1D3baPU0SMM3OyNM6MiIiEs06Pn/teLeYvGyvwBfpOy84oKxfMyOAzMzNZVJCC3RoRN1OG1KgaNO9kKcyIiEgkqGnr4akPKvnbpiqq23r6l7uibZw/LZ0VMzM5Y+LYCTYKMwMozIiISCQJBg3WH2zm5R21vLqznqbOfw0E64yycu6UNM6flsE5hanEOSKixcinojAzgMKMiIhEqkDQ4IOyFl7eUcsrO+to7PhXsLFbzCwsSOb8aemcPy2ddGdUCCsdegozAyjMiIjIaBAIGmyuaGX17npe31VHWXP3oPWzchM4f2oaZ01KZUa2K+JHVlaYGUBhRkRERhvDMNjf0Mnru+tZvbuerZVtg9bHO6zMz0tiYUEy8yYkMS3LiS3CRhhWmBlAYUZEREa7Bncvb+xp4M3iBjYcbKaj1z9ofbTNwqxcF6eNT2LuhEROHZeIKzq8J/NUmBlAYUZERMaSQNBgd42botImNpS2sKmilbZu36BtTCYoTI9n7vhE5k1IYnFhKgkx9hBVfGQKMwMozIiIyFgWDBocaOzkw/JWPixr5cPyFso/0t7GbjFz7pQ0Pn9qNosL08Ki+7fCzAAKMyIiIoM1dPSy+VC4eXd/E8V1Hf3rkmPtfGFeLl+aP47cpJiQ1agwM4DCjIjI2OHxByip6+BgUxflzd1UtnTT1uPD3eOj0+PHZAKLyYTNYiYp1k5KvIO0eAeF6fFMzXQyLikGc4T3Avo0dte4+ceWKp7bWtPf/dtkgnML07jq9PGcPTl1xHtHKcwMoDAjIjJ6ef1BNh5s4c3iBjZVtLKnxo03EPzU+4u1W5iS6WRappOpmU6mZTkpTI8n2j425knyB4K8saeBP20o5519/5r4MjcpmusX5fGlBeNGbM4ohZkBFGZEREafPbVu/lBUxovbaunwDO65kxRrZ2JaHBOSY8hNjCEpzo4zykZclBWMvgay3kCQ5k4PjZ1eatt6KK7roKS+A6//40HIbIK8lFimZbk4JdvFjGwX07OdOKPCuzfQyTrY1MWf1pfzzKYq2nv6GhCnOx3892emcsns7GH/fIWZARRmRERGj+ZOD99/YTf/3FbTvywlzs65U9I4Y2IKc3ITyU2KxmQ68Vsi/kCQ0qYudte42VPrZndt33NTp/eI2+elxDIjuy/gzMtLYnoEjuVyPHp9Af6+uZpfvbmPmvZeAP7feZO49fzJw/q5CjMDKMyIiIwOnR4/lz74HvsbOjGb4MIZmVy9cDzzJyQNazuXho5edte42VXjZkdVOzuq2wdNBHlYjN3C3PGJLMhLYt6EJGblJozYLZmR4PEHePDN/fzyzf2YTFB0x3lkuIZvCoXjPX+P3tmpRERk1Pnn1hr2N3SSEufg99edxik5CSPyuWnxUaQVRrG4MK1/WUuXlx3V7eysbmdLRSsflLXS3uPjnX1N/W1N7BYzp+T0XbWZP6FvsLpIvjXlsFqYn5cM7McwoNvr/8T3jASFGRERiRiBYF97lmi7mZzE0HUZhr52OedMTuWcyalA31guJfUdbCht5oOyVjaWtdDY4ekb26W8lYc4gMkEUzKczJ+QyPy8ZOblJZIWHxmTQx5s6uJXb+7n2c1VACydmk5eSmyIq+qj20wiIhIx2rq9XPCLd6hz9zIuKYbfXXsak9LjQ13WERmGQXlzNxsPtrCxrIUPyj4+UB3AhOSY/jmUTs9PJtMVHYJqj6zXF2BtcQN/21TFmyUNHE4MV87L5e7PTh/2W2hqMzOAwoyIyOixv6GD6x//gMqWHlzRNh67fh6njksMdVnHpcHd2xdsDrawsayV4jo3Hz0LT0iO4fT85P5wk+4c2Ss37d0+3t7XyNqSBlbvqh/UU+zcKWl849yJI/bzVpgZQGFGRGR0aeny8tUnPmBzRRvJsXbW3r44ItuitPf42FzeyvrSZopKm9lZ3U7wI2fl/JRYTi9IZtGhcJMS5xjaGrp9bK5sZVNZK0WlzWypaB1UQ5Yris/OzuaK03IoSI0b0s/+JAozAyjMiIiMPt1eP2fft46mTg+PXj2XZdMzQl3SSXP3+viwrIWiA82sL21hZ037x67cTEqLY1ZuAjMPjXeTlxJLYoztE7ui9/oC1LX3sq+hk731Heyt72B3jZt9DZ0f23ZyehyLC9NYOjWd08YnhmxEZPVmEhGRUcsXCPJkUTnNXX3D7odTO5OT4Yyyce6UdM6dkg70XbnZeLAv3Lx/oG/+pH0Nnexr6ORvm6r63xdrt5CVEE18lJVYhxWbxYzXH8TrD+Lu9VHv7qX1I7NmD5SfEsup4xM5bXwiZ01OJTshsn6eCjMiIhIx3L0+/r6piieKyjnY1AXAtQvHMzPHFeLKhocr2sb509I5f1pfuGnp8rKpvJUd1e3sqGpjd62bereHLm/giFdYPsphNVOQGsfk9DgmpcczJSOe2bkJJA/xrauRpjAjIjKK9foCVLZ090+6WN7SRWOHh+ZOL81dXtw9PryBIP6AQcAwiLZZiLVbiHFYSYi2kZkQTVZCFFmuaDJdUWQlRJOVEH1ctzWGwuEeQe8daOL1XfUUHWjun3cpKdbO7csLuXJe7rDXES6SYu2Dwg30HeOq1h7q2nvp9Pjp8vjxB4M4rBYcVjMxDisZzijSnQ5c0SNz3EaawoyIyCjh7vWxs6qdXTVudtX0PR9o7PxYg9Jj8fqD/XPwAFDeesTtom0WshP7gk12QjQ5iX2hJzshhuzEaFLi7DisJ9Zt1x8IUtnaw976DvbVd7C71s0HZa39MzgfNjk9jqtOH8/n5mQTH4GNfodalM3CxLQ4JqaNbOPccKIwIyISoY6nmy9AvMPKhJRYxifHMD45hgxXNMmxdpJj7bhibNgsZmxmM2Yz9PqCdHn8dHn9tHR5qW3rpaa9h5q2Hmrbe6lp66Wp00OPL8D+hk72H+PWRnyUlZQ4B8mxduKjrH1XCmxmrGYz3kAQjy9Ar79vssd6t4fmLs8R6z88iu65U9NYNi1jTJ+05cgUZkREIoTXH+TDshbWljSwtqTxiEEiJzGaGVkupmc5mZ7tZHqWi7R4x5DeWuj1BQ4Fmx6qW3uoauvp/7q6rYfa9h58AYOOXj8dvf7+ti3Hw2E1MzEtjsnp8UxOj2fu+EROyXGNqvmNZOgpzIiIhLFeX4A3ixt4YVsNb+9tpMsb6F9nMsHUDCfzD01qOG9CImkjMMBalM1CXkrsUYeyNwwDd4+fxk4PzZ0emjq9dHn9ePx9V2N8AQOH1YzDZibKaiEp1k5qvIN0ZxTJsfaQdQOWyKUwIyIShrZVtvHk+nJe21k3aATWlDgHiwtTWVKYxpkTU3DFhF+bEZPJhCvGhivGpltCMiIUZkREwkjRgWZ+/sZeNh5s6V92eATWz8zMYEaWS1cuRD5CYUZEJAx4/UG+99xOnvqwEgCbxcTFs7K4ct64kI7AKhIJFGZERMLAXf/sCzImE3x5wTi+sWQSGa6RnWBQJFIpzIiIhFggaPDMh31D0//ii7O5ZHZ2iCsSiSzmUBcgIjLWmU2QfqgX0t83V9PQ0RviikQii8KMiEiImUwmfnzZTOxWM2/tbWTJ/ev4+eq9dPQefWJAEfkXhRkRkTBw1qRU/vmNM5iV46LLG+D/1uzj7PvW8shbB+gZMLaMiHycyTCONHj06OJ2u3G5XLS3t+N0OkNdjojIURmGwcs76vjp6hJKG/tGzk2Jc/CNJQX824JxJzzfkUgkO97zt8KMiEgY8geCPLe1hl+8sZeq1h4ApmTE89BVc4868q7IaHO852/dZhIRCUNWi5nL5+bw5m2LuedzM0iOtVNc18EXHylSA2GRj1CYEREJY3armS8vGM/L/3EWE9PiaOjw8If3y0NdlkhYUZgREYkA6c4oThufCEBzlzfE1YiEl5CFmbKyMr7yla+Ql5dHdHQ0BQUF3HXXXXi9g39Jt2/fzllnnUVUVBS5ubncd999IapYRCR0/rapqn+qg+XT00NcjUh4CdkIwMXFxQSDQR555BEmTpzIzp07ufHGG+nq6uJ///d/gb6GP8uWLWPp0qU8/PDD7NixgxtuuIGEhAS+9rWvhap0EZER9YeiMu58fhcA1y2awOLCtBBXJBJewqo30/33389DDz1EaWkpAA899BDf+c53qKurw263A3DHHXfw3HPPUVxcfNz7VW8mEYlUv3/3ID94cTcAN5yRx/cumorJpEknZWyIyN5M7e3tJCUl9b8uKiri7LPP7g8yAMuXL6ekpITW1taj7sfj8eB2uwc9REQizY6qdv7npb4g8++LCxRkRI4ibMLM/v37eeCBB/j617/ev6yuro709MH3hg+/rqurO+q+7r33XlwuV/8jNzd3eIoWERlGr++uwzDg7Mmp3L68UEFG5CiGPMzccccdmEymYz4+eouourqaCy64gCuuuIIbb7zxpGtYtWoV7e3t/Y/KysqT3qeIyEjLdEUDsLm8lZd31BFGrQJEwsqQNwC+7bbbuO666465TX5+fv/XNTU1LFmyhEWLFvHoo48O2i4jI4P6+vpByw6/zsjIOOr+HQ4HDofjBCsXEQkvl8/N4YVtNRSVNnPLnzczPy+Jf19cwDmTU3WVRmSAIQ8zqamppKamHte21dXVLFmyhLlz5/LYY49hNg++ULRw4UK+853v4PP5sNlsAKxevZrCwkISExOHunQRkbBit5p54ob5/HLNPh59p5SNB1vYeLCFyelx3HBGHpfOySbKprmaRELWm6m6uprFixczfvx4nnjiCSyWf/1CHr7q0t7eTmFhIcuWLWPlypXs3LmTG264gZ///Ocn1DVbvZlEJNJVt/Xw+3cP8teNFXQdmkU7McbGlxaM4+rTJ5DhigpxhSJDL+wnmnz88ce5/vrrj7huYEnbt2/nlltu4YMPPiAlJYVvfvObrFy58oQ+S2FGREaL9h4fT39QyePvl1Hd1jcBpdVs4sKZmdxwxgTmjNNVaxk9wj7MjCSFGREZbfyBIG/sqef375Wx8WBL//I54xK4++LpzMpNCF1xIkNEYWYAhRkRGc12Vrfz2HtlvLCtBm8giMVs4sefn8kVp2lYColsETlonoiInLgZ2S5++oVZvHvHElackkkgaPDf/9hBXXtvqEsTGREKMyIio0RafBS/vHIOiTE2fAGDkvqOUJckMiIUZkRERpGfrS6htdtHtM3CKdmuUJcjMiIUZkRERok/ri/nwbUHAPifS2eQGGv/hHeIjA4KMyIio8Bru+q48/mdAPy/8yZx+dycEFckMnIUZkREIlyDu5f/+OsWggZcOS+X/1w6KdQliYwohRkRkQi3uaKNXl+QLFcUP7x0huZtkjFHYUZEJMLlp8YCUOvu5a8fVGp2bRlzFGZERCLc5PR4rls0AcOA7z63k+sf/4C96pYtY4jCjIjIKHDnRdNYecEUrGYT60oaueAXb3Pb09uobOkOdWkiw07TGYiIjCKljZ3c/1oJr+ysA8BmMfHFebl889xJpDs1s7ZEFs3NNIDCjIiMNVsr2/jp6yW8s68JAIfVzDULx/MfSycT57CGuDqR46MwM4DCjIiMVetLm/nf10r4sLwVgBnZTv76tYUKNBIRNNGkiIhwen4yz9y0kMeum0dSrJ2d1W6eLCoPdVkiQ0phRkRklDOZTMzPS2J8cgwALV2eEFckMrR0nVFEZBQLBA1e3lHL/a+VUNHSTZTNzBWn5Ya6LJEhpTAjIjIKNXV6eHZTFX/cUE5lSw8AGc4oHvjSHCanx4e4OpGhpTAjIjJKtHV7eW1XHS9sq+X9A00ED3XvcEXbuOGMPL56Vh6xavgro5D+VYuIRCjDMNhV42ZdSQPrShrZXNHaH2AAZuW4+NKCcXx2VjbRdkvoChUZZgozIiIRIhg02NfQycaDzWwsa2V9aTONHYMb807JiOfiWVlcdEom45NjQ1SpyMhSmBERCVOtXV52VLezo7qdrZVtfFDWQlu3b9A2MXYLZ0xMYXFhKosL08hOiA5RtSKhozAjIhJivb4ApY1dlDZ1cqChi+I6Nzuq26lq7fnYttE2C3PHJzI/L4n5eUnMGZeAw6pbSDK2KcyIyKjmDwQ50NjFrpp2ypu7qWvvpdbdS3uPj15vgF5/AK8/iMVswmE1Y7daDj2bcfQ/LP2vBz/3LbdbzDhsfc92qxmr2YzFbMJqNmE2Q68vSI83QI8vQEevn4aOXho6PDS6PVS39VDT3sPRxmKfkBzDjGwXp+S4mDchiRnZLmwWDREmMpDCjIiMOm3dXl7cXsuaPfUUlTbT6wuGuqRP5Iq2UZAaS35qHJPS4piZ7WJ6tgtXtC3UpYmEPYUZERk1erwBfv7GXp4sKqfHF+hfHmu3MD3LRUFaHFmuKDJcUSTG2ImyWYi2m7FbLPiCQbz+IB7/4efAJ7w+/Bi83OsPEjAMAkEDf9AgGDSIspmJtluJtpmJdVhJjXeQHh9FmtNBhjOKvJRYkmLtmEymEP70RCKXwoyIjAqdHj9XPlrEzmo30Ner57Ozszh3ShqT0+IxmxUUREYrhRkRGRUeXLufndVukmPt/OSyUzhvapqudIiMEQozIhLx/IEgz3xYCcAPL53B0mnpIa5IREaSmsSLSEQzDIPfv3eQpk4vSbF2BRmRMUhXZkQk4hiGQWVLD2/tbeDpD6vYUd0OwPWLJqjbssgYpDAjIsOuy+OnrLmrb4yX9l56B/Q0MplMmPq/BtOhZYZhEDD6hvD3BYO0dnlp7vRS1dbD3vqOQSPhOqxm/mPpJG4+p2BkvzERCQsKMyIy5Lq9ft7e28SaPfVsqWzjQGPnUQeF+7SsZhOnjk/kvClpXD43h+Q4x9B+gIhEDIUZERkyPd4AD63bz2Pvl9HR6x+0LjnWTmZCFBnOaOKjrBiGgQEYBoee+14DHP7CfGgUXYvZRFKsneRYO+nOKCalx1GQGkeUTcP4i4jCjIgMkfYeH1c+up49tX3jvOQkRrN8egZnTExmZnYCqfG6ciIiw0NhRkSGxC/X7GNPrZuUODs/uGQGF0zP0EB1IjIiFGZEZEjsqOrrUXT78kI+MzMzxNWIyFiiPowiMiTyUmIB2FzeFtpCRGTMUZgRkSFx2dwcAJ7fVk37gG7TIiLDTWFGRIbEvAmJTMmIp9cX5JlNlaEuR0TGkLAIMx6Ph9mzZ2Mymdi6deugddu3b+ess84iKiqK3Nxc7rvvvtAUKSLHZDKZuGR2NgAflLWEuBoRGUvCIsx8+9vfJisr62PL3W43y5YtY/z48WzatIn777+fu+++m0cffTQEVYrIsQSCBhsONgOQFh8V4mpEZCwJeW+mV155hddff51nn32WV155ZdC6P/3pT3i9Xn7/+99jt9uZPn06W7du5Wc/+xlf+9rXQlSxiHxUl8fPyme3s66kEZvFxDULx4e6JBEZQ0J6Zaa+vp4bb7yRJ598kpiYmI+tLyoq4uyzz8Zut/cvW758OSUlJbS2th51vx6PB7fbPeghIsNjW2UbFz/wLi9ur8ViNvGLL85hUnp8qMsSkTEkZGHGMAyuu+46brrpJk477bQjblNXV0d6evqgZYdf19XVHXXf9957Ly6Xq/+Rm5s7dIWLCAC+QJBfvLGXzz/0PqVNXWS6ovjLjaez4hSNMSMiI2vIw8wdd9zRNwvuMR7FxcU88MADdHR0sGrVqqEugVWrVtHe3t7/qKxUzwqRoVTa2MnlDxfxizf2EQgaXHRKJq/8x1nMz0sKdWkiMgYNeZuZ2267jeuuu+6Y2+Tn5/Pmm29SVFSEwzF4vpbTTjuNL3/5yzzxxBNkZGRQX18/aP3h1xkZGUfdv8Ph+Nh+ReTkGYbBH9eXc8/Le+j1BXFGWfmfS2f092ISEQmFIQ8zqamppKamfuJ2v/zlL/nhD3/Y/7qmpobly5fz1FNPsWDBAgAWLlzId77zHXw+HzabDYDVq1dTWFhIYmLiUJcuIp/gf18v4cG1BwA4c2IK919xCpmu6BBXJSJjXch6M40bN27Q67i4OAAKCgrIyekbSfRLX/oS3//+9/nKV77CypUr2blzJ//3f//Hz3/+8xGvV2Ssa+/28fBbpQCsunAKN56Vr4kkRSQshLxr9rG4XC5ef/11brnlFubOnUtKSgp33nmnumWLhECX108gaAAwd3yigoyIhA2TYRhGqIsYbm63G5fLRXt7O06nM9TliESsGx7/gDeLG7CYTXx5wTi+dnY+OYkfH1ZBRGQoHO/5W2FGRI5bt9fPymd38MK2GgAsZhPLp6dz+dwczp6UitUSFoOKi8gooTAzgMKMyNB6f38Tv153gHf3N/UvS4mz89lZ2aw4JZM5uQm6DSUiJ01hZgCFGZHhsafWzTMfVvH81mqau7z9y1PjHZw/LZ3l0zM4PT8Jh9USwipFJFIpzAygMCMyvHyBIG/vbeT5rTWsLW6gw+PvX+ewmjl1XCKn5yczd3wik9PjSI13YDLpyo2IHJvCzAAKMyIjx+MPUHSgmdd21fPGnnoaOzwf2yYhxkZOYjQpcQ5S4hzE2i3YrWYc1r7nKJuZWIeVOIeVWLv10PYxpMU7dPtKZAxRmBlAYUYkNAzD4EBjF+tLm1lf2syuGjflzV0EP+VfHbvVTH5KLKfkuJiVm8Dc8YkUpsfrKo/IKKUwM4DCjEj46PUFONDYSV17L02dHpo6vfR4A3gDQbz+IB5/gF5fkE6Pn65Dj+YuL7Xtvf3j3AyUFu/gzEkpnD0plbMmpZAcp6lMREYLhZkBFGZEIp8vEKSmrYeSug62VbWxtbKNTeWt9PqC/duYTXDahCSWHWp8nJukMXBEIpnCzAAKMyKjU68vwObyVt7e18TbexvZXesetH5KRjzLpmewfHo60zKduh0lEmEUZgZQmBEZG6rbeli9q47Xd9ez4WDLoNtS45JiuHhWJp+dlU1hRnwIqxSR46UwM4DCjMjY09btZc2eBl7fXcdbexsH3Y4qTI/ns7OzuHJertrYiIQxhZkBFGZExrYeb4A39tTzz201vFXSiDfQF2yibGauPyOP/1w6GbtVUzGIhBuFmQEUZkTksPYeH6/trOOPG8rZXtUOwLlT0vjdtaepTY1ImDne87f+KyIiY4or2sYX5uXy/C1n8PBVp2I1m3izuOFjjYdFJHIozIjImGQymbhgRiZZCdEAdPb6P+EdIhKuFGZEZExr7uybbiE1Xg2BRSKVwoyIjGlxUVYASuo6QlyJiHxaCjMiMqZ9/tQcAFb9Ywe7a9RuRiQSKcyIyJj2zXMnMis3gbZuH5c//D4vba8NdUkicoIUZkRkTIuxW/nD9fM5c2IK3d4At/x5M7c+tZX2Hl+oSxOR46QwIyJjnivGxmPXz+OWJQWYTfD3LdV85v/eYXNFa6hLE5HjoDAjIgLYLGZuXz6FZ25axLikGKrbevjCw0W8vEO3nUTCncKMiMgAc8cn8uL/O5PPzMzAHzS4/ZltdHk0Bo1IOFOYERH5CGeUjVvPnwxAlzdAnbs3xBWJyLFYQ12AiAhAl8dPvbuXli4vrd0+/IEgBmAC0pwOchJjSI1zYDYP7/xJpY2d/GlDBX9cXw7A9Cwnecmxw/qZInJyFGZEZMT1+gJsqWij6EATW6va2V/fQU37J1/9sFvN5CREk5MUQ05iNLmJh54PvU6OtZ/QZJGGYVDv9rCzup0PylpYV9JISf2/Bs9bVJDM/105Z9gDlIicHIUZERkxO6vbebKonJd21NJ5hHYocQ4rSbF2EmPtOCx9d8EDhkFdey+17T14/UFKm7oobeo64v6jbRYyXVGkO6PIcEXhirYRZbMQZTMTNPpCVI83QENHLzVtvVS1dtPaPbgLttkESwrTuOr08SwuTNVM2iIRQGFGRIadLxDkzud38ZeNFf3LUuMdLCpIZn5eEoXp8UxMiyMhxn7MfdS191LZ2k1VSw9Vrd1Uth56bumhvqOXHl/gmGHnSCxmE5PS4piZ7eKsyamcNTGFxNij1yEi4UdhRkSG3f2vlfQHmYtnZXHVgnHMz0s6oaseNouZ3KQYcpNioODj6z3+ADVtvdS191Lv7qW2vZdOj49eX5AeXwCLyUS03UKU1UxKvIMsVzSZCVEUpMYRZbMM1bcqIiGgMCMiw25tcQMAt50/mW+eN2lYPsNhtZCXEkteihrriow16potIsNu7vhEAB57v4z39zeFuBoRGW0UZkRk2K26cCozs120dHm56ncb+PW6/RiGEeqyRGSUUJgRkWHnirHx9NcX8oXTcggacN+rJfy/v27FHwiGujQRGQUUZkRkRETbLdx3+Szu+dwMrGYTL2yr4f7XS0JdloiMAgozIjKivrxgPP935RwAHnu3jNYub4grEpFIpzAjIiNuxSmZJMTY8AaCVLR0h7ocEYlwCjMiMuJe3VlLW7cPm8XEBM17JCInSWFGREbUG7vr+dZTWwG4/ow8XDG20BYkIhFPg+aJyIj568YK/vsfOwgacN6UNG5fXhjqkkRkFFCYEZER8dC6A/zk1WIAvnBaDvd8biY2iy4Oi8jJC/lfkpdeeokFCxYQHR1NYmIil1566aD1FRUVrFixgpiYGNLS0rj99tvx+z8+266IhK/Vu+v7g8wtSwr4yWWnKMiIyJAJ6ZWZZ599lhtvvJEf/ehHnHvuufj9fnbu3Nm/PhAIsGLFCjIyMnj//fepra3lmmuuwWaz8aMf/SiElYvIiXjmw0qg74rM7cunhLgaERltTEaIxhT3+/1MmDCB73//+3zlK1854javvPIKF110ETU1NaSnpwPw8MMPs3LlShobG7Hb7cf1WW63G5fLRXt7O06nc8i+BxE5Pt97bidPri8nOdbOqs9M5ZLZWboyIyKf6HjP3yH7a7J582aqq6sxm83MmTOHzMxMLrzwwkFXZoqKipg5c2Z/kAFYvnw5brebXbt2HXXfHo8Ht9s96CEiofOf509mSkY8zV1e/uuZbSy+fx0/W72XSo0xIyJDIGRhprS0FIC7776b7373u7z44oskJiayePFiWlpaAKirqxsUZID+13V1dUfd97333ovL5ep/5ObmDtN3ISLHIynWznO3nMHKC6aQEmenuq2HX67Zx1n3reULjxTxh6IyGjp6Q12miESoIQ8zd9xxByaT6ZiP4uJigsG+Cea+853vcNlllzF37lwee+wxTCYTzzzzzEnVsGrVKtrb2/sflZWVQ/GtichJiLJZuHlxAe+uPJf/u3I2Z01KwWSCjQdbuPP5XSz40RqufLSIJ9eX09jhCXW5IhJBhrwB8G233cZ11113zG3y8/Opra0FYNq0af3LHQ4H+fn5VFRUAJCRkcHGjRsHvbe+vr5/3dE4HA4cDsenKV9EhlmUzcIls7O5ZHY2NW09vLyjlpd21LKloo31pS2sL23hrud3siAvmaXT0jl3Shp5KRolWESObsjDTGpqKqmpqZ+43dy5c3E4HJSUlHDmmWcC4PP5KCsrY/z48QAsXLiQe+65h4aGBtLS0gBYvXo1TqdzUAgSkciUlRDNV8/K56tn5VPV2s0rO+p4cUct2yrbKCptpqi0mf95cTf5KbEsmZLGWZNSmJObqFGDRWSQkPVmAvjWt77F3/72N37/+98zfvx47r//fl544QWKi4tJTEwkEAgwe/ZssrKyuO+++6irq+Pqq6/mq1/96gl1zVZvJpHIUtnSzWu76lhb0sDGgy34AoP/TBWkxjI108n45BjGJ8WSnRhNpiuKTFc00XZLiKoWkaF2vOfvkIYZn8/HqlWrePLJJ+np6WHBggX84he/YPr06f3blJeXc/PNN7Nu3TpiY2O59tpr+fGPf4zVevwXlRRmRCJXR6+Pd/c18WZxAx+UtVDWfOweUIkxNjJdh8JNQl/AGZcUw7wJSWS4okaoahEZChERZkaKwozI6NHS5WVbZRv7Gzopb+mivLmbmrYeatt76fYGjvneCckxnDM5lQtmZDI/LwmL2TRCVYvIp6EwM4DCjMjoZxgG7h4/Ne091Lb3hZvatl5q2nvYV9/Jrpp2ggP+2iXH2lk+I4PLTs3m1HGJmEwKNiLhRmFmAIUZEXH3+thQ2sJru+pYvbue9h5f/7q8lFg+Pyebz52aTU5iTAirFJGBFGYGUJgRkYF8gSDrS5v5x5ZqXt1ZN+j21ML8ZK5ZOJ5l0zN0G0okxBRmBlCYEZGj6fL4eWVnHc9uqqKotLl/eW5SNF87K58vLRivUCMSIgozAyjMiMjxqGrt5i8bK/jThgrauvtuQ83KTeB3155GSpwG4hQZaWE/0aSISLjJSYzh9uVTKLrjPO6+eBrxUVa2VbZxx7PbQ12aiByDwoyIyEdE2y1cd0Yeqy6cCsDWyvYQVyQixzLk0xmIiES6Xl+Ax98v4+er9wJw3pS0EFckIseiMCMickh7t49nNlXy6NulNByaufvcKWnc9VnNBScSzhRmRGRMCwYNPixv5a8fVPDS9lo8/iAAma4obj1/MpfPzdGAeiJhTmFGRMYcwzDYUtnGi9tqeXlHLXXu3v51UzLiuWbhBC6bm43DqkkrRSKBwoyIjAlef5APylp4Y089r++qp7qtp39dnMPKBTMy+NKCcczJTdCVGJEIozAjIqNWS5eXtcUNvFncwNt7G+nw+PvXxdotLJ2WzoqZmZw9OZUom67CiEQqhRkRGTUMw2BvfSdriutZs6eBzRWtDBwWNCXOzpLCNM6bms7iQgUYkdFCYUZEIprHH2B9aQtv7qlnTXEDVa09g9ZPy3Ry3tS+AHNKtguzpiYQGXUUZkQk4jR09LKuuJE1xfW8s69p0ESRDquZMyamsGRKGudNSSMrITqElYrISFCYEZGIUFLXwWu76lhT3MC2yrZB69KdDs6dks55U9I4Y2IK0XbdPhIZSxRmRCRs1bT18M9tNTy3pZriuo5B607JcXHelHTOm5rG9CyneiCJjGEKMyISVoJBg7f2NvL79w7y7v6m/ga8douZsyensHRqOudOSSPNGRXaQkUkbCjMiEhYMAyD13bVc/9rxRxo7OpfPj8vic/NyeYzMzJxxdhCWKGIhCuFGREJuU6Pn2/9dQtv7GkAIN5h5Yvzcrl20QRyk2JCXJ2IhDuFGREJKcMw+Pc/bebtvY3YLWa+dnY+Xz8nn/goXYURkeOjMCMiIVXT3svbexsBeOrrpzNnXGKIKxKRSGMOdQEiMrY5o6w4rH1/ip7+sIquAVMOiIgcD4UZEQmp+Cgbd108HZMJ/rKxgnPuX8cf15fj9QdDXZqIRAiFGREJuS8tGMcT189nQnIMTZ0evvvcTs772Tqe3VRFIGh88g5EZEwzGYYx6v9SuN1uXC4X7e3tOJ3OUJcjIkfh9Qf584ZyfrX2AE2dHgAKUmP51tLJrJiZqXmVRMaY4z1/K8yISNjp8Qb4Q1EZD711gLZuHwBTMuK58+JpLCpICXF1IjJSjvf8rdtMIhJ2ou0Wvn5OAe98ewn/uXQy8Q4rxXUdXP27jby0vTbU5YlImFGYEZGwFR9l4z+WTuKdlUu4dHYWgaDBqr9vp2fALNkiIgozIhL2EmLs/OTyU7CYTbh7/VS1doe6JBEJIwozIhIRfvb6XgJBg8QYm6Y4EJFBFGZEJOz99p1SHnm7FIC7PzudKJslxBWJSDhRmBGRsPa3TVX88KU9ANy+vJBLZmeHuCIRCTcKMyIStmraelj19+0A3HhWHv++uCDEFYlIOFKYEZGw9WF5K76AQW5SNP/9mamYTBo0T0Q+TmFGRMLWlIx4ACpbevjBi7s1CaWIHJHCjIiErcnp8dy+vBCAx94r45z71/Lbd0px9/pCXJmIhBNNZyAiYW9tcQN3v7CL8ua+8WVi7RYum5vDtYsmUJAaF+LqRGS4aG6mARRmRCKfLxDk2U1V/O7dg+xr6Oxffs7kVK4/YwJnT0rVRJQio0xEzM20d+9eLrnkElJSUnA6nZx55pmsXbt20DYVFRWsWLGCmJgY0tLSuP322/H7dd9cZKyxWcxcOX8cr//n2fzpqwtYOjUNkwne2tvIdY99wPk/f4sn15fj8WuqA5GxJqRh5qKLLsLv9/Pmm2+yadMmZs2axUUXXURdXR0AgUCAFStW4PV6ef/993niiSd4/PHHufPOO0NZtoiEkMlk4oyJKfz22nms+6/F3HBGHvEOKwcau/jecztZ/vO3eXdfU6jLFJERFLLbTE1NTaSmpvL2229z1llnAdDR0YHT6WT16tUsXbqUV155hYsuuoiamhrS09MBePjhh1m5ciWNjY3Y7fbj+izdZhIZ3To9fv72YSW/XneAhg4PZhP86kun8pmZmaEuTUROQtjfZkpOTqawsJA//OEPdHV14ff7eeSRR0hLS2Pu3LkAFBUVMXPmzP4gA7B8+XLcbje7du066r49Hg9ut3vQQ0RGrziHlevOyOPN/1rMpbOzCBrwPy/uDnVZIjJCQhZmTCYTb7zxBlu2bCE+Pp6oqCh+9rOf8eqrr5KYmAhAXV3doCAD9L8+fCvqSO69915cLlf/Izc3d/i+EREJG3EOK0un9f2NcPf4GAP9G0SEYQgzd9xxByaT6ZiP4uJiDMPglltuIS0tjXfeeYeNGzdy6aWXcvHFF1NbW3tSNaxatYr29vb+R2Vl5RB9dyISzl7ZUcutT28D4IvzxmnEYJExwjrUO7ztttu47rrrjrlNfn4+b775Ji+++CKtra3998F+/etfs3r1ap544gnuuOMOMjIy2Lhx46D31tfXA5CRkXHU/TscDhwOx8l9IyISMQzD4IE39/Oz1XsBOH9aOisvLAxxVSIyUoY8zKSmppKamvqJ23V39w1+ZTYPvjhkNpsJBoMALFy4kHvuuYeGhgbS0tIAWL16NU6nk2nTpg1x5SISiXp9AW7/23Ze2FYDwHWLJvDdFVOxWjTAuchYEbLf9oULF5KYmMi1117Ltm3b2Lt3L7fffjsHDx5kxYoVACxbtoxp06Zx9dVXs23bNl577TW++93vcsstt+jKi4jQ0evji48U8cK2GqxmEz/63Ezu/ux0BRmRMSZkv/EpKSm8+uqrdHZ2cu6553Laaafx7rvv8vzzzzNr1iwALBYLL774IhaLhYULF3LVVVdxzTXX8IMf/CBUZYtIGHnkrVK2VbXjirbx5FcW8KUF40JdkoiEwJDfZjoRp512Gq+99toxtxk/fjwvv/zyCFUkIpFkS2UrAN9YMpGFBckhrkZEQkXXYkUkYk3PcgHwyNulbCpvCXE1IhIqCjMiErG+ce5EpmTE09Tp4fKHi1j19+3UtPWEuiwRGWEKMyISsZxRNp6+aSGXz83BMOAvGytZfP867v7nLho7PKEuT0RGSMjmZhpJmptJZPT7oKyF+18rYePBvttNMXYLXzkzjxvPzscZZQtxdSLyaRzv+VthRkRGDcMweHd/E//7WgnbqtoBSImz88t/m8OigpQQVyciJyrsJ5oUERlqJpOJsyal8twtZ/DwVXPJT42lqdPLdb//gOI6TTgrMlopzIjIqGMymbhgRgYvffMs5o5PxBsI8syHVaEuS0SGicKMiIxamytaOdjUBUBqvEYNFxmtQjponojIcNhU3srDbx1g9e6+iWlnZDu5ZuH4EFclIsNFYUZERoXmTg8vbKvh2c3V7Kjua/xrNsFVp49n5QVTiLHrz53IaKXfbhGJWDVtPazZU8/ru+spOtCMP9jXOdNmMXHp7Gy+dnY+k9LjQ1yliAw3hRkRiRi9vgCbylt5b38Tb+9rZGf14B5KM7NdXHZqNhfPyiI5Tm1kRMYKhRkRCVtdHj/bqtrYVNbK+wea2VTRitcf7F9vMsGp4xI5f1o6509LpyA1LoTVikioKMyISFjwBYKUNnaxvaqNzRVtbKloZW99B8GPDOuZ7nRwRkEKiyamsLgwlRRdgREZ8xRmRMaIQNCg1xfAAGJsFsxmU0jq6PL4qWrtobKlm30NnZTUuSmu6+BAYye+wMcHJM9OiGb2uAROz09mUUEy+SmxmEyhqV1EwpPCjMgo0t7jY1tlG9sq29jb0El1azfVbT20dfvwDLg9A31zF8U6rMT2P1uJdViIsVuJtluIsVv6nm1Wou1mLGYzFhNYzCbMZhMW08Bn8AcMfAEDfzCI1x+k1xegtdtHa7eXtm4fzZ0eqlp7aO7yHrX+OIeVaZlO5oxLYM64ROaMSyDdGTXcPzYRiXAKMyIRzhcI8s+tNTy3tZr3DzQT+Oh9maPo9gbo9gZoHOb6jsQZZSU3KYa8lFimZjopTI+nMCOenMRoXXURkROmMCMSwbZUtPKtp7ZS3tzdv2x8cgyzcxOYlukkNymG7IRokuPsfVdcbBYAurx+uj0BOj1+urx+ujx+ujyBQ8v9dPsC9Hj7Hoe/DgQNAoZBMGgQCBoEDePQsr4JHi1mEzaLGZul7znKaiEh1kZCtJ3EGBtJsXayE6PJSYzBFa1ZrEVk6CjMiESosqYuvvSbDfT4AqTE2bl24QQumpVFXkrsJ7432m4BdfwRkVFCYUYkQv1lYwU9vgCnjkvgiRvmEx+lqx0iMjZpokmRCLW3vgOAy+fmKsiIyJimMCMSgXyBIHtq+8JMblJ0iKsREQkt3WYSiSDuXh9v7K7n0bdLqXP3EmUzMy3TGeqyRERCSmFGZAgYhkGdu5eath4a3B4aOjx09PaN7eL1B/EHDaJtlv7xW2I/OpaL3UqM3YLDau4fq6XLE6Cxo5d6t4d9DR3sqnGzo6q9fzLFhBgbP//ibM1BJCJjnsKMyAlq6fKyp9bNnlo3JXUd7GvoZH9DJ50e/4h8fkFqLJfOzuaq08eTGGsfkc8UEQlnCjMiR3F4rqDiOje7a90U13awp9ZNQ4fniNtbzCYyXVGkxTtIi4/CFW3DYTPjsJoxm030Hhqk7vC4LV0ePz2+vmU93gA9vgBefxCrxYTVbCbKZiYt3kFqvIMJybFMy3IyJzeRcckxI/yTEBEJbwozMub1eAOUNXdxsKnvcaCxk+LaDvY3dOINBI/4nvHJMUzJiGdKhpPCjHgmpsUxITkWu1Vt6kVERprCjIwZ/kCQvfWdbK1sY1dNe394qW3vPep74hzWvtCSGc/UTGd/eIlz6FdHRCRc6C+yjFrBoMHOmnbWlTTy7r4mtle30es78pWWhBgbeSmxfY/kWCZnxDMt00l2QnTIZpcWEZHjozAjo86eWjdPf1jJC9tqaOocPENzvMPKKbkuTslJYGJqHHmpfeFFDWlFRCKXwoyMGlsr27jv1WLeP9DcvyzWbuGMiSksLkxjfl4i+SlxutIiIjLKKMzIqPDg2v387+slGAbYLCaWTk3nitNyOHNiqhrlioiMcgozEvFe21XH/a+VAHDp7Cz+a3khOYnqviwiMlYozEjEe3VnHQD/Nj+Xez9/SoirERGRkabr7xLx0p1RAJTUdRA8NNS/iIiMHQozEvGuWzSBGLuFzRVtPP1hZajLERGREaYwIxEvwxXFredPBuDeV4rp8QZCXJGIiIwkhRkZFaZkOAFo7/HR3HXkuZNERGR0UgNg+dQMw6Cp00tZcxd17b20dHlp7vLi7vHhDwYJBA2CQUiItZEWf3gCRgdpzr6vY09ySoDGDg/v7W/i2c1VvLOvCYCzJ6eSnRA9FN+eiIhECIUZOS5ef5CSug62V7exo6qd3bVuDjZ20eHxf+p9xtot/cHm8HNSrJ3EGDtJsTYcNkv/th29ftq6vdS7eznQ0MXehg5KG7v615tMcOW8XL530TRMJg2KJyIylgxbmLnnnnt46aWX2Lp1K3a7nba2to9tU1FRwc0338zatWuJi4vj2muv5d5778Vq/VdZ69at49Zbb2XXrl3k5uby3e9+l+uuu264ypZDOj1+NpW3sqG0mY0HW9he1X7EGaRNJshOiCYrIZrkWDtJsXYSYmzYLGYsJhMmE7R0+ajv6KXR7aGho5eGDg/d3gBd3kD/ZI+f1rRMJ0unpnH53FzGJWtsGRGRsWjYwozX6+WKK65g4cKF/O53v/vY+kAgwIoVK8jIyOD999+ntraWa665BpvNxo9+9CMADh48yIoVK7jpppv405/+xJo1a/jqV79KZmYmy5cvH67Sx6SOXh8bD7aw4WALG0qb2VnjJvCRbs6uaBun5LiYmd33KEiLY1xSDFEDrqAcr06PnwZ3L/WHAk5jh4eGDg8tXV7aur20dvvw+oMYGBgGxEdZSYyxkxxnJz8ljolpcczIdpGkOZVERMY8k2EYwzowx+OPP863vvWtj12ZeeWVV7jooouoqakhPT0dgIcffpiVK1fS2NiI3W5n5cqVvPTSS+zcubP/fVdeeSVtbW28+uqrx12D2+3G5XLR3t6O0+kcku8r0nn9QbZWtvHu/ibe29/E1sq2j4WXnMRoFuQlsyAviXl5SUxIjtEtHBERGTHHe/4OWZuZoqIiZs6c2R9kAJYvX87NN9/Mrl27mDNnDkVFRSxdunTQ+5YvX863vvWtY+7b4/Hg8fyrR4vb7R7S2iNVZUs3r+2q4739TWw42EL3R7owj0+OYVFBMvPzkpifl6yGtCIiEhFCFmbq6uoGBRmg/3VdXd0xt3G73fT09BAdfeST7b333sv3v//9Yag68jR09PLclmpe2lHHtsq2QeuSY+0smpjCmROTWVSQQm6S2pyIiEjkOaEwc8cdd/CTn/zkmNvs2bOHKVOmnFRRJ2vVqlXceuut/a/dbje5ubkhrGjk7W/o4NfrDvDCthp8gb7bR2YTLMhL5twpaZwxMYUpGfGYzbptJCIike2Ewsxtt932iT2J8vPzj2tfGRkZbNy4cdCy+vr6/nWHnw8vG7iN0+k86lUZAIfDgcPhOK46RptA0OCnr5fw6Nul+A+1gTl1XAKfm5PNBTMySY0fmz8XEREZvU4ozKSmppKamjokH7xw4ULuueceGhoaSEtLA2D16tU4nU6mTZvWv83LL7886H2rV69m4cKFQ1LDaLTy2e38bVMVAEunpvGNcycxOzchtEWFqT9tKGdcUgyLClKw6AqViEjEGrY2MxUVFbS0tFBRUUEgEGDr1q0ATJw4kbi4OJYtW8a0adO4+uqrue+++6irq+O73/0ut9xyS/9VlZtuuolf/epXfPvb3+aGG27gzTff5Omnn+all14arrIj2u4aN3/bVIXZBD//4mwumZ0d6pLCVqfHzw9f3EOPL0CGM4rPn5rNv80fp3ZDIiIRaNjmZrrzzjuZM2cOd911F52dncyZM4c5c+bw4YcfAmCxWHjxxRexWCwsXLiQq666imuuuYYf/OAH/fvIy8vjpZdeYvXq1cyaNYuf/vSn/Pa3v9UYM0dR2doNwOT0eAWZT9DrC3D53Bxc0Tbq3L38et0Bzrl/LTf/cRMHGjtDXZ6IiJyAYR9nJhyMlXFmKlu6Oeu+tVjMJjZ/73xc0bZQlxT2PP4Ab+5p4M8bK/rnd7JZTPz486dw2dycEFcnIjK2He/5W7NmjyK5STHkp8QSCBq8vbcx1OVEBIfVwoUzM3nyKwt47Vtns7gwFV/AYOWz26lt7wl1eSIichwUZkaJYNBg9e566ty9AHSdxASQY1VhRjw/+txMAPxBg+pWhRkRkUigWbOHWZfHz4HGTho7PDR3emnr8eIP9s03BH1zDrmibSTE2Pueo20kxNiIj7Ids4dNr69vksa99R18UNbC2uJGqtv6Tr5TMuK5aFbWSHx7o4Y/EOTF7bX84MXdAOSnxnJKTkJoixIRkeOiMDPEWru8vFncwLq9jWytbKWy5dP9795kgniHlYQYOw6rGfOhGai7vQHaur24ez9+5SU+ysqXFozjm+dOIs6hQ3s8erwBntlUyW/eKe0/VlMznTx69VzsVl24FBGJBDrjDZHmTg//+3oJf99cjccfHLQuNd5BpiuK5Fg7CTF2rGYTZpMJAwN3j5/2Hh9tPT7cPT5au710ewMYBrh7/UcMLYc5o6wUpMUxKyeBRQXJnD059VPNYD0WtXZ5+UNROU8UldHS5QUgKdbODWdM4Maz83FY9XMUEYkUCjNDoLa9h0sffI96d9/kllMy4lk6NZ2FBclMzXSSFGs/of15/UHcvT7aun2093j7wpEBQQOi7RYSYmwkxthJjLFpFusTVNnSze/ePchTH1TS4+ubaDM3KZqvnZXP5XNzibYrxIiIRBqFmSHwyFul1Ls9jE+O4f7LZzFvQuJJhQy71UxKnIOUOE09MFR21bTz6NulvLi9lsChaR6mZzm56ZwCLpyRgdWiW0oiIpFKYWYI9B76H/6MbBfz85JCXI0M9GFZC79au591Jf/qqn7mxBRuOqeAMyYm68qWiMgooDAzBK6cP46nPqzkpe21fG52PUunpYe6pDFvW2Ub976yh/WlLUDfjOGfmZnJTecUMCPbFeLqRERkKCnMDIHZuQl89cw8fvPOQe74+3ZeG3c2ybpFFBI93gA/eHE3f/2gAsPoG833slNzuOmcAiakxIa6PBERGQYKM0PktmWFvL23iZL6Du58fhcPfvnUUJc05rR2efnSbzewp9YNwOfnZPNfywvJSogOcWUiIjKc1OpxiETZLPz0C7MAeGVnLe09vhBXNPbc8fft7Kl1kxLn4M83LuBnX5ytICMiMgYozAyhqZlO7FYzQYP+sUtkZHj8AV7fXQ/A7687jUUFKSGuSERERorCzBD64/pyvP4grmgb2boiMKIsJhNx9r67putLm0NcjYiIjCSFmSHyjy1V3P3CLgD+33mTNBT+CLNazNy8pACAH71czLf/tq2/y7yIiIxuOuMOgT9vqODWp7dhGPBv88dx/aIJoS5pTLr5nAJuX16I2QRPf1jF5Q+/3z/5poiIjF4KMyfpd+8e5L//sQPDgKtPH889l87AfIzZrmX4mEwmblkykT/csICkWDs7q91c+uB7CjQiIqOcwsxJ+MeWKv7nxd0AfP3sfH5wyXQFmTBw5qQU/vmNM5iUFkdjh4f/e2NvqEsSEZFhpHFmTsI/ttQAcOnsLO64cMqYGBo/GDRo7/HR0u2ltctLp8ePP2DgCwTxBQ3sFhPRdisxdgtxDivpzqiQTIiZGu9gUnoc+xo6aejwjOhni4jIyFKYOQn5KbG8vbeR1bvreeDN/Vx1+vgTniE73BiGQWOHh/2NnVS2dFPZ0kNFSzeVrd1UtfbQ3Onh0DyNx81uMZPmdDAhOZaJaXFMSo9jUlo8k9PjSIgZ2p9XvbuXF7bV8Nh7Zf23l65aMH5IP0NERMKLyTCMEzw1RR63243L5aK9vR2n0zlk+23v8fG1P3zIhoN98//YLWbOn5bOxbOyOGdyKtF2y5B91nBo7/axt6GDkrpDj/oO9tZ30Nb9yQP+xUdZSYq1E2u3YrOasVtMWMwmfAGDbm+AHq+f9h4frZ+wr3Sng8np8RSmxzM5o+95UnocMfZPztmBoEFVazd76zv5sKyF9aXNbK9u5/C/6HSngx9cMoPl0zOO6+chIiLh5XjP3wozJykYNHhhew2/eaeUndXu/uXRNgtLpqRywYxMzp2SRpwjdBfBerwB9h0KLXvrOyip72RvXQd17t4jbm82wfjkWMYlxZCbFN33nBhDblIMaU4HCdH24+567vEHaHB7qHP3crCxi30NHexr6GRffedRG+aaTJDliiY5zk5ijB1ntI3DN6l6fQFau700d3mpbu3B4w9+7P1zxyfyuTnZXD43hyhbeAdKERE5OoWZAYYzzAy0q6adv2+u5tWddYNO1DaLiXkTklhcmMriwjQmpcUNSxuSQNCgvLmLkroOigdcbSlr7uJoRzk7IZrJ6XH9V0UKM+IpSI0bkRDQ0etjX0NfsCqp/1fYauo8/tGT7VYz+SmxzMpJYEF+EqfnJ2sKAxGRUUJhZoCRCjOHGYbBzmo3r+ys5dWddZQ2dQ1an+WKYtHEFGbnJjA7N4HCjHhsluPvWNbW7eVgUxflzd2Hnrsobepib30Hvb6PX6kASIq194eVyYeeJ6XH4YyyndT3OhyaOj2UN3fT1u2lpcuLu9ffv85uMZEU6yAp1k6mK4rcpBgs6kEmIjIqKcwMMNJh5qMONnWxrqSBdSWNrC9t/titEYvZRFZCFLmJMSTG2om1W4iyWfAFgnj8QXq8AZo6PTR1emns8NDp8R/lkyDKZmZyel9gmZLRF1oKM+JJjXOMid5WIiIyeijMDBDqMDNQjzfA+oPNbC5vZWtlG1sr2+joPXo4OZoMZxTjk2PIS4llQkosE5JjKcyIZ5yuVIiIyChxvOdvdc0eYdF2C0sK01hSmAb0NSBu7PT0dYNu7aa920eXN0CvL4DNYsZuNRNts5AS5yAlzk5qvIMMV9Rx9fYREREZC3RGDDGz2US6M4p0ZxSnTUgKdTkiIiIRR9MZiIiISERTmBEREZGIpjAjIiIiEU1hRkRERCKawoyIiIhENIUZERERiWgKMyIiIhLRFGZEREQkoinMiIiISERTmBEREZGIpjAjIiIiEU1hRkRERCKawoyIiIhEtDExa7ZhGAC43e4QVyIiIiLH6/B5+/B5/GjGRJjp6OgAIDc3N8SViIiIyInq6OjA5XIddb3J+KS4MwoEg0FqamqIj4/HZDKN6Ge73W5yc3OprKzE6XSO6GfLJ9PxCW86PuFNxyf8RfoxMgyDjo4OsrKyMJuP3jJmTFyZMZvN5OTkhLQGp9MZkf+Qxgodn/Cm4xPedHzCXyQfo2NdkTlMDYBFREQkoinMiIiISERTmBlmDoeDu+66C4fDEepS5Ah0fMKbjk940/EJf2PlGI2JBsAiIiIyeunKjIiIiEQ0hRkRERGJaAozIiIiEtEUZkRERCSiKcwMo89+9rOMGzeOqKgoMjMzufrqq6mpqRm0zfbt2znrrLOIiooiNzeX++67L0TVji1lZWV85StfIS8vj+joaAoKCrjrrrvwer2DttPxCZ177rmHRYsWERMTQ0JCwhG3qaioYMWKFcTExJCWlsbtt9+O3+8f2ULHsAcffJAJEyYQFRXFggUL2LhxY6hLGpPefvttLr74YrKysjCZTDz33HOD1huGwZ133klmZibR0dEsXbqUffv2habYYaIwM4yWLFnC008/TUlJCc8++ywHDhzg8ssv71/vdrtZtmwZ48ePZ9OmTdx///3cfffdPProoyGsemwoLi4mGAzyyCOPsGvXLn7+85/z8MMP89///d/92+j4hJbX6+WKK67g5ptvPuL6QCDAihUr8Hq9vP/++zzxxBM8/vjj3HnnnSNc6dj01FNPceutt3LXXXexefNmZs2axfLly2loaAh1aWNOV1cXs2bN4sEHHzzi+vvuu49f/vKXPPzww2zYsIHY2FiWL19Ob2/vCFc6jAwZMc8//7xhMpkMr9drGIZh/PrXvzYSExMNj8fTv83KlSuNwsLCUJU4pt13331GXl5e/2sdn/Dw2GOPGS6X62PLX375ZcNsNht1dXX9yx566CHD6XQOOmYyPObPn2/ccsst/a8DgYCRlZVl3HvvvSGsSgDjH//4R//rYDBoZGRkGPfff3//sra2NsPhcBh/+ctfQlDh8NCVmRHS0tLCn/70JxYtWoTNZgOgqKiIs88+G7vd3r/d8uXLKSkpobW1NVSljlnt7e0kJSX1v9bxCW9FRUXMnDmT9PT0/mXLly/H7Xaza9euEFY2+nm9XjZt2sTSpUv7l5nNZpYuXUpRUVEIK5OPOnjwIHV1dYOOlcvlYsGCBaPqWCnMDLOVK1cSGxtLcnIyFRUVPP/88/3r6urqBv0hBvpf19XVjWidY93+/ft54IEH+PrXv96/TMcnvOn4hE5TUxOBQOCIP3/97MPL4eMx2o+VwswJuuOOOzCZTMd8FBcX929/++23s2XLFl5//XUsFgvXXHMNhgZdHjYnenwAqqurueCCC7jiiiu48cYbQ1T52PBpjo+IyCexhrqASHPbbbdx3XXXHXOb/Pz8/q9TUlJISUlh8uTJTJ06ldzcXNavX8/ChQvJyMigvr5+0HsPv87IyBjy2seCEz0+NTU1LFmyhEWLFn2sYa+Oz9A70eNzLBkZGR/rPaPjMzJSUlKwWCxH/P3Qzz68HD4e9fX1ZGZm9i+vr69n9uzZIapq6CnMnKDU1FRSU1M/1XuDwSAAHo8HgIULF/Kd73wHn8/X345m9erVFBYWkpiYODQFjzEncnyqq6tZsmQJc+fO5bHHHsNsHnyhUsdn6J3M789HLVy4kHvuuYeGhgbS0tKAvuPjdDqZNm3akHyGHJndbmfu3LmsWbOGSy+9FOj7+7ZmzRq+8Y1vhLY4GSQvL4+MjAzWrFnTH17cbjcbNmw4ak/BiBTqFsij1fr1640HHnjA2LJli1FWVmasWbPGWLRokVFQUGD09vYahtHXojw9Pd24+uqrjZ07dxp//etfjZiYGOORRx4JcfWjX1VVlTFx4kTjvPPOM6qqqoza2tr+x2E6PqFVXl5ubNmyxfj+979vxMXFGVu2bDG2bNlidHR0GIZhGH6/35gxY4axbNkyY+vWrcarr75qpKamGqtWrQpx5WPDX//6V8PhcBiPP/64sXv3buNrX/uakZCQMKh3mYyMjo6O/t8PwPjZz35mbNmyxSgvLzcMwzB+/OMfGwkJCcbzzz9vbN++3bjkkkuMvLw8o6enJ8SVDx2FmWGyfft2Y8mSJUZSUpLhcDiMCRMmGDfddJNRVVU1aLtt27YZZ555puFwOIzs7Gzjxz/+cYgqHlsee+wxAzjiYyAdn9C59tprj3h81q5d279NWVmZceGFFxrR0dFGSkqKcdtttxk+ny90RY8xDzzwgDFu3DjDbrcb8+fPN9avXx/qksaktWvXHvF35dprrzUMo6979ve+9z0jPT3dcDgcxnnnnWeUlJSEtughZjIMtUYVERGRyKXeTCIiIhLRFGZEREQkoinMiIiISERTmBEREZGIpjAjIiIiEU1hRkRERCKawoyIiIhENIUZERERiWgKMyIiIhLRFGZEREQkoinMiIiISERTmBEREZGI9v8BAB0//wSIePsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Normalise and print our generated data.\"\"\"\n",
        "\n",
        "# Normalise the angles by dividing by pi, and the velocity by dividing by 100.\n",
        "@jit\n",
        "def modulo_two_pi(x):\n",
        "  return x % (2 * pi)\n",
        "\n",
        "# Normalise our generated data. We normalise the angles by modulo-ing the angles by 2 pi, dividing by pi (so that values are between 0 and 2), and then subtracting 1,\n",
        "# so that the valeus are between -1 and 1. To normalise the angular velocities, divide by 100.\n",
        "@jit\n",
        "def normalise_data(generated_data):\n",
        "  normalised_data = generated_data\n",
        "  normalised_data = normalised_data.at[:,:2].apply(modulo_two_pi)\n",
        "  normalised_data = normalised_data.at[:,:2].divide(pi)\n",
        "  normalised_data = normalised_data.at[:,:2].add(-1)\n",
        "\n",
        "  normalised_data = normalised_data.at[:,2:].divide(pi)\n",
        "\n",
        "  return normalised_data\n",
        "\n",
        "normalised_data = normalise_data(generated_data)\n",
        "plt.plot(normalised_data[:, 0], normalised_data[:, 1])\n",
        "\n",
        "# Before we split the data, we need to actually package it into short ordered batches. The idea is we will have:\n",
        "# the dataset: [y0, y1, .... , yt], where yi = (theta_1i, theta_2i, omega_1i, omega_2i)\n",
        "# which will then be packaged into smaller, ordered time series batches like this:\n",
        "# z0 = [y0, y1, ... , yn], z1 = [y(n+1), y(n+2), ... , y(2n)] etc.\n",
        "# And these can then be put into training batches as we would expect normally.\n",
        "\n",
        "@jit\n",
        "def order_batches(normalised_data):\n",
        "  ordered_batches = []\n",
        "  for i in range(data_points - prediction_batch_size - 1):\n",
        "    ordered_batches.append(normalised_data[i:i + prediction_batch_size,:])\n",
        "\n",
        "  ordered_batches = jnp.array(ordered_batches)\n",
        "  return ordered_batches\n",
        "\n",
        "ordered_batches = order_batches(normalised_data)\n",
        "\n",
        "# Split the data. We need shuffle to be 0 to preserve the time series.\n",
        "x_train, x_test = train_test_split(ordered_batches, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "zJXcW076yN2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build The Model"
      ],
      "metadata": {
        "id": "XjWXaS99tgB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Define our dataset class. This allows us to batch our data when training.\"\"\"\n",
        "\n",
        "class Dataset:\n",
        "  \"\"\"An iterator over a numpy array, revealing batch_size elements at a time.\"\"\"\n",
        "  # Initialise our dataset class. It needs the full x and y values and a batch size to be initialised.\n",
        "  def __init__(self, x: jnp.array, batch_size: int):\n",
        "    self._x = x\n",
        "    self._batch_size = batch_size\n",
        "    self._length = self._x.shape[0]\n",
        "    # The id stores where the next datapoint should be taken from, so when initialised it should be 0.\n",
        "    self._idx = 0\n",
        "\n",
        "  # This is the function that gives us our next batch of data.\n",
        "  def __next__(self):\n",
        "    # Start again from beginning of dataset if there are not enough datapoints in front.\n",
        "    if self._idx + self._batch_size >= self._length:\n",
        "      self._idx = 0\n",
        "\n",
        "    # Select the first and last datapoints in the batch. First will be the current value of the ID\n",
        "    start = self._idx\n",
        "    end = start + self._batch_size\n",
        "    # Select our data.\n",
        "    x= self._x[start:end]\n",
        "    # This resets us back to 0 once we reach the end of our data.\n",
        "    if end >= self._length:\n",
        "      end = end % self._length\n",
        "      # assert end == 0  # Guaranteed by ctor assertion.\n",
        "    self._idx = end\n",
        "    return x"
      ],
      "metadata": {
        "id": "Gd2Y9WtYxQcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Now that we have defined our dataset class, we can make our datasets.\"\"\"\n",
        "\n",
        "train_dataset = Dataset(x_train, training_batch_size)\n",
        "eval_dataset = Dataset(x_test, training_batch_size)"
      ],
      "metadata": {
        "id": "1XEhn7Goj8Cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Define our batch and trainingstate class.\"\"\"\n",
        "\n",
        "# Define a batch of data.\n",
        "class Batch(NamedTuple):\n",
        "  input: np.ndarray\n",
        "  output: np.ndarray\n",
        "\n",
        "# Define a training state, telling us what parameters we have and the state of the optimizer.\n",
        "class TrainingState(NamedTuple):\n",
        "  params: hk.Params\n",
        "  opt_state: optax.OptState"
      ],
      "metadata": {
        "id": "ZoB9o03CmvqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Define the neural network and set our optimizer.\"\"\"\n",
        "\n",
        "def FeedForward(x):\n",
        "  mlp = hk.Sequential([\n",
        "      hk.Linear(32), jax.nn.sigmoid,\n",
        "      hk.Linear(32), jax.nn.leaky_relu,\n",
        "      hk.Linear(32), jax.nn.sigmoid,\n",
        "      hk.Linear(2),\n",
        "  ])\n",
        "  return mlp(x)\n",
        "\n",
        "# Define our network and optimiser.\n",
        "network = hk.without_apply_rng(hk.transform(FeedForward))\n",
        "optimiser = optax.adam(1e-2)"
      ],
      "metadata": {
        "id": "jveNOFup1cqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Define our mean squared error loss function.\"\"\"\n",
        "\n",
        "@jit\n",
        "def nn_predict(x, t, weights):\n",
        "  # Our network only predicts the acceleration. Since we are using odeint on it, we need input and output to be the same shape, so we can attach the velocities directly\n",
        "  # onto it too. We also need to normalise our inputs.\n",
        "  x = x.at[:2].add(1)\n",
        "  x = x.at[:2].apply(modulo_two)\n",
        "  x = x.at[:2].add(-1)\n",
        "  veloc = x[2:]\n",
        "  accel = network.apply(weights, x)\n",
        "  y = jnp.hstack((veloc, accel))\n",
        "  return y\n",
        "\n",
        "@jit\n",
        "def modulo_two(x):\n",
        "  return x % 2\n",
        "\n",
        "@jit\n",
        "def normalise_predictions(preds):\n",
        "  preds = preds.at[:,:2].add(1)\n",
        "  preds = preds.at[:,:2].apply(modulo_two)\n",
        "  preds = preds.at[:,:2].add(-1)\n",
        "  return preds\n",
        "\n",
        "@jit\n",
        "def minimum_difference(truth, preds):\n",
        "  difference_1 = jnp.absolute(truth - preds)\n",
        "  difference_2 = jnp.absolute(truth - preds + (2*pi))\n",
        "  difference_3 = jnp.absolute(truth - preds - (2*pi))\n",
        "  return jnp.minimum(difference_3, jnp.minimum(difference_1, difference_2))\n",
        "\n",
        "batch_tsteps = jnp.array([i*dt for i in range(prediction_batch_size)])\n",
        "\n",
        "@jit\n",
        "def MeanSquaredErrorLoss(weights, batch, tsteps=None):\n",
        "\n",
        "  # This array will hold our predictions for each prediction batch.\n",
        "  preds = []\n",
        "  # Make our predictions. Our output data is periodic between (-1, 1), but odeint doesn't know that it has to stay within these bounds. Thus,\n",
        "  # we will have to manually normalise it. To do this, we can add 1 so it is periodic between (0, 2), module by 2, and then subtract 1 again.\n",
        "  for i in range(batch.shape[0]):\n",
        "    if tsteps != None:\n",
        "      prediction = odeint(nn_predict, batch[i, 0], tsteps, weights)\n",
        "      batch = odeint(dy_dt, batch[i, 0], tsteps, g)\n",
        "    else:\n",
        "      prediction = odeint(nn_predict, batch[i, 0], batch_tsteps, weights)\n",
        "    prediction = normalise_predictions(prediction)\n",
        "    # This adds the prediction for batch i to the preds tuple.\n",
        "    preds.append(prediction)\n",
        "\n",
        "  preds = jnp.array(preds)\n",
        "  difference = minimum_difference(batch, preds)\n",
        "\n",
        "  return jnp.power(difference, 2).mean()"
      ],
      "metadata": {
        "id": "1HoiXNA_2mzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Define what happens at each gradient update.\"\"\"\n",
        "\n",
        "@jit\n",
        "def update(state: TrainingState, batch: Batch) -> TrainingState:\n",
        "  # This is how we define our stochastic gradient descent.\n",
        "\n",
        "  # Find grads of loss w.r.t parameters, on this batch of the data\n",
        "  grads = jax.grad(MeanSquaredErrorLoss)(state.params, batch)\n",
        "  # Get the updates and the new optimser state from this.\n",
        "  updates, opt_state = optimiser.update(grads, state.opt_state)\n",
        "  # Apply the updates to the parameters.\n",
        "  params = optax.apply_updates(state.params, updates)\n",
        "\n",
        "  #return the training state with the new parameters and the optimiser.\n",
        "  return TrainingState(params, opt_state)"
      ],
      "metadata": {
        "id": "9Qe0bcrc28Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Initialise our parameters and print the shape of our network.\"\"\"\n",
        "\n",
        " #Initialising the parameters randomly.\n",
        "rng = jax.random.PRNGKey(12)\n",
        "initial_params = network.init(rng, x_train[1])\n",
        "\n",
        "# Initialise the optimiser and the define the state.\n",
        "initial_opt_state = optimiser.init(initial_params)\n",
        "state = TrainingState(initial_params, initial_opt_state)\n",
        "\n",
        "# Print the structure of the network.\n",
        "print(\"Weights Type : {}\\n\".format(type(initial_params)))\n",
        "\n",
        "for layer_name, weights in initial_params.items():\n",
        "    print(layer_name)\n",
        "    print(\"Weights : {}, Biases : {}\\n\".format(initial_params[layer_name][\"w\"].shape,initial_params[layer_name][\"b\"].shape))"
      ],
      "metadata": {
        "id": "dZm9BX5x2_D_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Define lists to store our loss over time in. This is not in the cell below so that we can run our training loop multiple times and keep the losses.\"\"\"\n",
        "\n",
        "train_loss_list = []\n",
        "val_loss_list = []\n",
        "second_loss_list = []\n",
        "energy_list = []\n",
        "action_list = []"
      ],
      "metadata": {
        "id": "hE9prG1bd_--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating Action and Energy"
      ],
      "metadata": {
        "id": "0mX4bZl0SJ5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can check the legitimacy of our system by seeing if it minimises action and conserves the energy. To calculate the action of our system, we first need the Lagrangian of our system. Our Lagrangian is defined as:\n",
        "\n",
        "$$ L = T - V $$\n",
        "\n",
        "Similarly, our total energy (which should be conserved) is:\n",
        "\n",
        "$$ E = T + V $$\n",
        "\n",
        "Where $T$ is Kinetic Energy and $V$ is Potential Energy. The Kinetic Energy of the system is just the sum of the kinetic energies for each mass. Since the mass is normalised at 1, this is:\n",
        "\n",
        "$$ \\begin{align} T & = \\frac{1}{2} v_1^2 + \\frac{1}{2} v_2^2 \\\\ & = \\frac{1}{2} (\\dot{x}_1^2 + \\dot{y}_1^2 ) + \\frac{1}{2} ( \\dot {x}_2^2 + \\dot{y}_2^2 ) \\end{align} $$\n",
        "\n",
        "The Potential Energy of the system is just the gravitational potential energy as there are no other factors at play. Since our masses and lengths are both normalised at 1, this will be:\n",
        "\n",
        "$$ V = g y_1 + g y_2 $$\n",
        "\n",
        "We can define the $x$'s and $y$'s as just the angles $ \\theta_1, \\theta_2 $ since the radius is constant at 0. $x_1$ and $y_1$ are easy to define, since they rotate around a fixed point:\n",
        "\n",
        "$$ \\begin{align} x_1 & = \\sin{\\theta_1} \\\\ y_1 & = - \\cos{\\theta_1} \\end{align} $$\n",
        "\n",
        "For $x_2$ and $y_2,$ we must add the $x_1$ and $y_1$ values to them respectively, to account for the fact that the axis is not fixed:\n",
        "\n",
        "$$ \\begin{align} x_2 & = \\sin{\\theta_1} + \\sin{\\theta_2} \\\\ y_2 & = - \\cos{\\theta_1} - \\cos{\\theta_2} \\end{align} $$\n",
        "\n",
        "And these values can be differentiated to find their time derivatives:\n",
        "\n",
        "$$ \\begin{align} \\dot{x}_1 & = \\dot{\\theta}_1 \\cos{\\theta_1} \\\\ \\dot{y}_1 & = \\dot{\\theta}_1 \\sin{\\theta_1} \\\\ \\dot{x}_2 & = \\dot{\\theta}_1 \\cos{\\theta}_1 + \\dot{\\theta}_2 \\cos{\\theta}_2 \\\\ \\dot{y}_2 & = \\dot{\\theta}_1 \\sin{\\theta_1} + \\dot{\\theta}_2 \\sin{\\theta_2} \\end{align} $$\n",
        "\n",
        "We can calculate our Lagrangian and integrate along this over every point in our trajectory to calculate the action, i.e. calculate the Lagrangian at every point and sum these multiplied by $dt.$\n",
        "\n",
        "The principle of least action states that if a system evolves from point $x_0$ at time $t_0$ to point $x_1$ at time $t_1$, the path that it takes will be the path that minimises the action. Thus, the idea is that you can tell if the system is improving by seeing if the action minimises to the same value. But this only works if the path always ends at the same point, while our ode solver doesn't actually ensure this."
      ],
      "metadata": {
        "id": "F2p7k9_NmdKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First create a function to convert our angles and angular velocities to Cartesian Coordinates.\n",
        "@jit\n",
        "def cartesian(theta):\n",
        "  # First we have to 'un normalise' our data by adding 1 to the angles and multiplying everything by 2 pi.\n",
        "  theta = theta.at[:2].add(1)\n",
        "  theta = theta * pi\n",
        "\n",
        "  theta_1 = theta[0]\n",
        "  theta_2 = theta[1]\n",
        "  omega_1 = theta[2]\n",
        "  omega_2 = theta[3]\n",
        "\n",
        "  x_1 = sin(theta_1)\n",
        "  y_1 = - cos(theta_1)\n",
        "\n",
        "  x_2 = sin(theta_1) + sin(theta_2)\n",
        "  y_2 = - cos(theta_1) - cos(theta_2)\n",
        "\n",
        "  dxdt_1 = omega_1 * cos(theta_1)\n",
        "  dydt_1 = omega_1 * sin(theta_1)\n",
        "\n",
        "  dxdt_2 = omega_1 * cos(theta_1) + omega_2 * cos(theta_2)\n",
        "  dydt_2 = omega_1 * sin(theta_1) + omega_2 * sin(theta_2)\n",
        "  return [x_1, y_1, x_2, y_2, dxdt_1, dydt_1, dxdt_2, dydt_2]\n",
        "\n",
        "@jit\n",
        "def kinetic_energy(x):\n",
        "  kinetic = 1/2 * (x[4]**2 + x[5]**2 + x[6]**2 + x[7]**2)\n",
        "  return kinetic\n",
        "\n",
        "@jit\n",
        "def potential_energy(x):\n",
        "  potential = g * (x[1] + x[3])\n",
        "  return potential\n",
        "\n",
        "@jit\n",
        "def total_energy(theta):\n",
        "  x = cartesian(theta)\n",
        "  kinetic = kinetic_energy(x)\n",
        "  potential = potential_energy(x)\n",
        "  return kinetic + potential\n",
        "\n",
        "@jit\n",
        "def lagrangian(theta):\n",
        "  x = cartesian(theta)\n",
        "  kinetic = kinetic_energy(x)\n",
        "  potential = potential_energy(x)\n",
        "  return kinetic - potential\n",
        "\n",
        "# The action of the system is the weighted sum of the lagrangians.\n",
        "@jit\n",
        "def action(data):\n",
        "  action = 0.\n",
        "  for i in range(data.shape[0]):\n",
        "    action = action + dt * lagrangian(data[i])\n",
        "  return action"
      ],
      "metadata": {
        "id": "N344maJtmNbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Run the training & evaluation loop.\"\"\"\n",
        "actual_energy = total_energy(normalised_data[0])\n",
        "print(\"actual energy = \", actual_energy)\n",
        "for step in range(gradient_updates):\n",
        "  # Do stochastic gradient descent on a batch of training examples.\n",
        "  state = update(state, next(train_dataset))\n",
        "\n",
        "  # Print the training and evaluation loss every 1000 time steps. We normalise the loss so that if we change batch size, the loss stays at the same scale.\n",
        "  if step % 100 == 0:\n",
        "    # First use odeint on our network to calculate a path, so we can evaluate the action and energy for this path.\n",
        "    data = next(train_dataset)[0]\n",
        "    predicted_data = odeint(nn_predict, data[0], batch_tsteps, state.params)\n",
        "    predicted_data = normalise_predictions(predicted_data)\n",
        "    # We evaluate the energy at the last prediction point, as this should be where the error is largest.\n",
        "    energy_list.append(total_energy(predicted_data[-1]))\n",
        "\n",
        "    # We care about whether the difference between real and predicted action is decreasing, since the action will be different for each prediction batch.\n",
        "    action_list.append(action(predicted_data) - action(data))\n",
        "\n",
        "    # We need a way of comparing the loss of one network to another. This cannot be done by taking the training loss as this will vary depending on the length of time that\n",
        "    # we predict over. Thus, we will make a '1 second loss' which is the loss from the prediction in 1 seconds time.\n",
        "\n",
        "    second_loss_list.append(MeanSquaredErrorLoss(state.params, jnp.array([data]), jnp.array([0., 1.])))\n",
        "\n",
        "    train_loss_list.append(MeanSquaredErrorLoss(state.params, next(train_dataset)) / (training_batch_size * prediction_batch_size))\n",
        "    val_loss_list.append(MeanSquaredErrorLoss(state.params, next(eval_dataset)) / (training_batch_size * prediction_batch_size))\n",
        "    print(\"Step {}: train loss {}, eval loss {}, 1 second loss {}, energy {}, action {}\".format(step, train_loss_list[-1], val_loss_list[-1], second_loss_list[-1], energy_list[-1], action_list[-1]))"
      ],
      "metadata": {
        "id": "ThKKvvcr3BDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " \"\"\"Plot our losses, energy and change in action\"\"\"\n",
        "\n",
        "plt.plot(train_loss_list, color=\"b\", label=\"training loss\")\n",
        "plt.plot(val_loss_list, color=\"r\", label=\"validation loss\")\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "plt.plot(second_loss_list, color=\"b\")\n",
        "plt.title(\"Loss of Predicted Point 1 second after IV\")\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "plt.plot(energy_list, label=\"Energy of prediction\")\n",
        "plt.plot((0, len(energy_list)), (actual_energy, actual_energy), label=\"True Energy\")\n",
        "plt.title(\"Energy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "plt.plot(action_list, label=\"Change in Action\")\n",
        "plt.plot((0, len(action_list)), (0, 0), label=\"0\")\n",
        "plt.title(\"Action of predicted path - true action\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "91VswHF87esZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Create graphs showing how well our model does, and evaluate loss from each of these graphs.\"\"\"\n",
        "\n",
        "# How many points to print / generate for our graphs.\n",
        "display_data_points = 20000\n",
        "\n",
        "# Our first graph will be comparing the full length of training data to predictions of this.\n",
        "predicted_data = odeint(nn_predict, normalised_data[0], tsteps[:display_data_points], state.params)\n",
        "predicted_data = normalise_predictions(predicted_data)\n",
        "\n",
        "# Print the loss on this full length of the dataset.\n",
        "print(\"total dataset loss: \", jnp.power(normalised_data[:display_data_points,:2] - predicted_data[:,:2], 2).mean())\n",
        "\n",
        "# The graph looks very messy if the number of points is large, so we only print the first display_data_points of the data.\n",
        "plt.plot(predicted_data[:display_data_points, 0], predicted_data[:display_data_points, 1], color=\"blue\", label=\"Predicted\")\n",
        "plt.plot(normalised_data[:display_data_points, 0], normalised_data[:display_data_points, 1], color=\"red\", label=\"Truth\", linestyle=\"dashed\")\n",
        "plt.plot(normalised_data[0,0], normalised_data[0,1], \"o\", color=\"green\")\n",
        "plt.legend()\n",
        "plt.title(\"plot from start of training data\")\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "# The second graph will be using the same generated data, but only displaying as many points as are in the prediction batches.\n",
        "plt.plot(predicted_data[:prediction_batch_size, 0], predicted_data[:prediction_batch_size, 1], color=\"blue\", label=\"Predicted\")\n",
        "plt.plot(normalised_data[:prediction_batch_size, 0], normalised_data[:prediction_batch_size, 1], color=\"red\", label=\"Truth\", linestyle=\"dashed\")\n",
        "plt.plot(normalised_data[0,0], normalised_data[0,1], \"o\", color=\"green\")\n",
        "plt.legend()\n",
        "plt.title(\"Batch size plot from start of training data\")\n",
        "plt.show()\n",
        "plt.close()\n",
        "\n",
        "# The final graph will be from a newly generated set of data.\n",
        "\n",
        "# Generate our initial datapoints and normalise these.\n",
        "init_eval = generate_initial_point(False, perturb=-pi)\n",
        "generated_eval_data = odeint(dy_dt, init_eval, tsteps, g)\n",
        "normalised_eval_data = normalise_data(generated_eval_data)\n",
        "\n",
        "# Use our network to make predictions on this and normalise those.\n",
        "predicted_eval_data = odeint(nn_predict, normalised_eval_data[0], tsteps, state.params)\n",
        "predicted_eval_data = normalise_predictions(predicted_eval_data)\n",
        "\n",
        "# Plot this data\n",
        "plt.plot(predicted_eval_data[:display_data_points, 0], predicted_eval_data[:display_data_points, 1], color=\"blue\", label=\"Predicted\")\n",
        "plt.plot(normalised_eval_data[:display_data_points, 0], normalised_eval_data[:display_data_points, 1], color=\"red\", label=\"Truth\", linestyle=\"dashed\")\n",
        "plt.plot(normalised_eval_data[0,0], normalised_eval_data[0,1], \"o\", color=\"green\")\n",
        "plt.legend()\n",
        "plt.title(\"Random Starting point.\")\n",
        "plt.show()\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "GsDw0VV2BK-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbolic Regression\n"
      ],
      "metadata": {
        "id": "Tdj7yrO6V63g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gplearn.genetic import SymbolicRegressor\n",
        "import graphviz\n",
        "# Generate some random points.\n",
        "symb_key = jax.random.PRNGKey(14)\n",
        "symb_input = jax.random.uniform(key=symb_key, shape=(100, 4), minval=0, maxval=2*pi)\n",
        "\n",
        "symb_input_normalised = normalise_data(symb_input)\n",
        "symb_output = network.apply(state.params, symb_input_normalised) * 2 * pi\n",
        "\n",
        "est_gp = gp.genetic.SymbolicRegressor(function_set=['add', 'sub', 'mul', 'div', 'sin', 'cos'], population_size=5000,\n",
        "                           generations=20, stopping_criteria=0.01,\n",
        "                           p_crossover=0.7, p_subtree_mutation=0.1,\n",
        "                           p_hoist_mutation=0.05, p_point_mutation=0.1,\n",
        "                           max_samples=0.9, verbose=1,\n",
        "                           parsimony_coefficient=0.01, random_state=0)\n",
        "\n",
        "est_gp.fit(symb_input, symb_output[:,0])\n",
        "\n",
        "idx = est_gp._program.parents['donor_idx']\n",
        "fade_nodes = est_gp._program.parents['donor_nodes']\n",
        "dot_data = est_gp._programs[-2][idx].export_graphviz(fade_nodes=fade_nodes)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ],
      "metadata": {
        "id": "Cmn104PfWCwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create animation of the pendulums"
      ],
      "metadata": {
        "id": "rfOB9ttM3E23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code below will convert the data into a gif."
      ],
      "metadata": {
        "id": "MdfpoSvDceut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to Cartesian coordinates of the two bob positions.\n",
        "\n",
        "theta_1 = (1 + predicted_data[:,0]) * pi\n",
        "theta_2 = (1 + predicted_data[:,1]) * pi\n",
        "\n",
        "Theta_1 = generated_data[:,0]\n",
        "Theta_2 = generated_data[:,1]\n",
        "\n",
        "x1 = sin(theta_1)\n",
        "y1 = cos(theta_1)\n",
        "x2 = x1 + sin(theta_2)\n",
        "y2 = y1 + cos(theta_2)\n",
        "\n",
        "X1 = sin(Theta_1)\n",
        "Y1 = cos(Theta_1)\n",
        "X2 = X1 + sin(Theta_2)\n",
        "Y2 = Y1 + cos(Theta_2)\n",
        "\n",
        "# Plotted bob circle radius\n",
        "r = 0.05\n",
        "# Plot a trail of the m2 bob's position for the last trail_secs seconds.\n",
        "trail_secs = 1\n",
        "# This corresponds to max_trail time points.\n",
        "max_trail = int(trail_secs / dt)\n",
        "\n",
        "def make_plot(i):\n",
        "    # Plot and save an image of the double pendulum configuration for time\n",
        "    # point i.\n",
        "    # The pendulum rods.\n",
        "    ax.plot([0, x1[i], x2[i]], [0, y1[i], y2[i]], lw=2, c='k')\n",
        "    # Circles representing the anchor point of rod 1, and bobs 1 and 2.\n",
        "    c0 = Circle((0, 0), r/2, fc='k', zorder=10)\n",
        "    c1 = Circle((x1[i], y1[i]), r, fc='b', ec='b', zorder=10)\n",
        "    c2 = Circle((x2[i], y2[i]), r, fc='r', ec='r', zorder=10)\n",
        "    ax.add_patch(c0)\n",
        "    ax.add_patch(c1)\n",
        "    ax.add_patch(c2)\n",
        "\n",
        "    ax.plot([0, X1[i], X2[i]], [0, Y1[i], Y2[i]], lw=2, c='k')\n",
        "    c3 = Circle((X1[i], Y1[i]), r, fc='g', ec='g', zorder=10)\n",
        "    c4 = Circle((X2[i], Y2[i]), r, fc='y', ec='y', zorder=10)\n",
        "    ax.add_patch(c3)\n",
        "    ax.add_patch(c4)\n",
        "\n",
        "    # The trail will be divided into ns segments and plotted as a fading line.\n",
        "    ns = 20\n",
        "    s = max_trail // ns\n",
        "\n",
        "    for j in range(ns):\n",
        "        imin = i - (ns-j)*s\n",
        "        if imin < 0:\n",
        "            continue\n",
        "        imax = imin + s + 1\n",
        "        # The fading looks better if we square the fractional length along the\n",
        "        # trail.\n",
        "        alpha = (j/ns)**2\n",
        "        ax.plot(x2[imin:imax], y2[imin:imax], c='r', solid_capstyle='butt',\n",
        "                lw=2, alpha=alpha)\n",
        "\n",
        "        ax.plot(X2[imin:imax], Y2[imin:imax], c='y', solid_capstyle='butt',\n",
        "                lw=2, alpha=alpha)\n",
        "\n",
        "    # Centre the image on the fixed anchor point, and ensure the axes are equal\n",
        "    ax.set_xlim(-2-r, 2+r)\n",
        "    ax.set_ylim(-2-r, 2+r)\n",
        "    ax.set_aspect('equal', adjustable='box')\n",
        "    plt.axis('off')\n",
        "    plt.savefig('img{:04d}.png'.format(i//di), dpi=72)\n",
        "    plt.plot()\n",
        "    plt.cla()\n",
        "\n",
        "\n",
        "# Make an image every di time points, corresponding to a frame rate of fps\n",
        "# frames per second.\n",
        "# Frame rate, s-1\n",
        "fps = 10\n",
        "di = int(1/fps/dt)\n",
        "fig = plt.figure(figsize=(8.3333, 6.25), dpi=72)\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "for i in range(0, tsteps.size, di):\n",
        "    print(i // di, '/', tsteps.size // di)\n",
        "    make_plot(i)"
      ],
      "metadata": {
        "id": "Da-1HEW4ocKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames = []\n",
        "for i in range(483):\n",
        "  image = imageio.v2.imread(f'img{i:04}.png')\n",
        "  frames.append(image)\n",
        "\n",
        "imageio\n",
        "imageio.mimsave('./example.gif', # output gif\n",
        "                frames,          # array of input frames\n",
        "                fps = 10)         # optional: frames per second\n",
        "\n"
      ],
      "metadata": {
        "id": "cp42dUo572Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AGb6Yf4SqdzV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}